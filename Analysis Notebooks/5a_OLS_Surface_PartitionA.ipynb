{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebooks uses Partition A Surface Data with the OLS model to make snowfall predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import necessary modules and the ASOS/SNOTEL dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dtb\n",
    "import os\n",
    "from glob import glob\n",
    "import datetime as dt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# OLS Analysis of meteorological variables and snowfall (Training Dataset: 2008-2017 only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will first utilize just the Copper Mountain surface level variables and run the model explicitly to generate statistics.  This will give snowfall predictive capability of individual meteorological variables (Dewpoint, SNOTEL Temperature, Temperature, Wind Speed, Cloud Cover, Wind Direction, 6hr Pressure change, and Pressure) using an OLS model and the 2008-2017 training dataset. The resulting values will also be used to verify some code which performs same analysis, but with a loop.  This code will then be fed all upper air and surface level variables to determine best combination of variables in the OLS model.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define dataframe which contains these features with concurrent snowfall events**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [pd.read_csv('test_train_df.dat', parse_dates = True, index_col = 'Date_Time')]\n",
    "test_train_df = pd.concat(data)\n",
    "print(len(test_train_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This matches calculations made in the snowfall statistics analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as sts\n",
    "all_yrs_tt = (test_train_df.index >= '01-01-2006') & (test_train_df.index < '01-01-2018')\n",
    "test_yrs_tt=  (test_train_df.index >= '01-01-2015')\n",
    "train_yrs_tt = (test_train_df.index >= '01-01-2006') & (test_train_df.index < '01-01-2015')\n",
    "\n",
    "print(len(test_train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform forward step feature selection using the OLS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define surface features which have high data capture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['CMtnSNTL_Temp_degC', 'CMtn_Temperature_degC', 'CMtn_Dewpoint_degC', \\\n",
    "'CMtn_WindDirection_deg', 'CMtn_WindSpeed_mps', 'LXV_Temperature_degC', 'LXV_Dewpoint_degC', \\\n",
    "'LXV_Pressure_hp', 'LXV_WindSpeed_mps', 'LXV_WindDirection_deg', 'LXV_12hr_delta_Pressure_hp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now use a forward selection methodology using the surface features and the OLS model.  Feature combinations which result in higher adjusted R squared values will be kept to train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Import statsmodel\n",
    "\n",
    "import statsmodels.api as sm\n",
    "#import statsmodel\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "variables_org = variables\n",
    "\n",
    "\n",
    "print('******')\n",
    "adjRs = []\n",
    "newRs = []\n",
    "dup_var = []\n",
    "max_vars = []\n",
    "f_pvalues = []\n",
    "\n",
    "while variables != []:\n",
    "  #print(variables)\n",
    "  for var in variables:\n",
    "\n",
    "        \n",
    "    #print(variables)\n",
    "    max_var = max(variables, key = lambda v: ols('CMtnSNTL_Upcoming12hrSNOWFALL_gte3_in ~' + v, test_train_df[train_yrs_tt]).fit().rsquared_adj)    #this finds OLS model run with highest adj R squared\n",
    "    OLS = ols('CMtnSNTL_Upcoming12hrSNOWFALL_gte3_in ~' + max_var, test_train_df[train_yrs_tt]).fit()\n",
    "    \n",
    "    print(max_var)\n",
    "    #print(max_var)\n",
    "    #print(OLS.rsquared)\n",
    "    \n",
    "    #Create lists of statistics for each combination of variables modeld\n",
    "    adjRs.append(OLS.rsquared_adj)\n",
    "    f_pvalues.append(OLS.f_pvalue)\n",
    "    max_vars.append(max_var)\n",
    "\n",
    "    add_max_var = '+ '+ max_var\n",
    "    \n",
    "    variables = [s + add_max_var for s in variables_org]\n",
    "    \n",
    "    #The above for loop naturally will create a duplicate variable, which should be removed\n",
    "    for v in variables_org: \n",
    "      dup_var = []\n",
    "      dup_var = [var for var in variables if var.count(v)>1]\n",
    "      if dup_var!=[]:\n",
    "            for dup in dup_var: variables.remove(dup)\n",
    "\n",
    "#combine the modeled variable sequences with respective stats  \n",
    "stats = list(zip(adjRs, f_pvalues))    # create list of tuples\n",
    "dictionary = OrderedDict(zip(max_vars, stats))\n",
    "#dictionary_adjRs = OrderedDict(zip(max_vars, f_pvalues))\n",
    "#print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the adjusted R square calculated for each iteration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(adjRs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the adjusted F statistic calculated for each iteration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f_pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print adjusted R and F stat probabilities in order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for c in dictionary:\n",
    "    #print(str(dictionary.keys().index(c))+\"{country}: {capital}\".format(country=c, capital=dictionary[c])+\"\\n\")\n",
    "        print(str(list(dictionary.keys()).index(c))+ \" {key} \\n Adjusted R: {adjR}  Fstat(prob): {f_pvalue}\".format(key=c, adjR=dictionary[c][0], f_pvalue = dictionary[c][1])+\"\\n\")\n",
    "        OLS = ols('CMtnSNTL_Upcoming12hrSNOWFALL_gte3_in ~' + c, test_train_df[train_yrs_tt]).fit()\n",
    "\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find max adj R and obtain OLS summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Just use 'min' instead of 'max' for minimum.\n",
    "print(\"Print maximum:\")\n",
    "maximum = max(dictionary, key=dictionary.get) \n",
    "print(maximum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thus the feature set with best capability looks to be these four features.  Let's look at the statsmdel regression results when just these features are used:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_all_str = max(dictionary, key=dictionary.get) \n",
    "print(maximum_all_str)\n",
    "\n",
    "maxOLS_all = ols('CMtnSNTL_Upcoming12hrSNOWFALL_gte3_in ~' + maximum_all_str , test_train_df[train_yrs_tt]).fit() \n",
    "print(maxOLS_all.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We do note that some of the individual feature p values are still a little hight. Let's test different P|t| thresholds for which to remove variables, rerun and model for each set of variables, and see what threshold might glean best results using adjusted R squared as a metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rsq_adj = maxOLS_all.rsquared_adj\n",
    "thresh = 0\n",
    "\n",
    "goodp_str = maximum_all_str\n",
    "highp_var = []\n",
    "\n",
    "maximum_all_str = max(dictionary, key=dictionary.get)    #this is the string of variables found in previous OLS run associated with mad adjusted R squared.\n",
    "#print(maximum_all_str)\n",
    "\n",
    "print(maxOLS_all.pvalues[1])\n",
    "for test_thresh in range(1, 100):   #loop through different P|t| thresholds ranging from 1 to 100.  Note floats are not allowed here \n",
    "  #print(test_thresh)\n",
    "  highp_var = [var for var in maxOLS_all.pvalues.keys() if maxOLS_all.pvalues[var]>=test_thresh*0.01]  #check P|t| for each variable against threshold and store in list\n",
    "  #print(highp_var)\n",
    "  \n",
    "  testgoodp_str = maximum_all_str   #reset testgoodp_str \n",
    "    \n",
    "  for var in highp_var:\n",
    "    testgoodp_str = testgoodp_str.replace(var+\"+ \", \"\")  # if need to replace first feature in string\n",
    "    testgoodp_str = testgoodp_str.replace(\"+ \" + var, \"\")   #  \n",
    "    \n",
    "    print(var)\n",
    "    print(testgoodp_str)\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "  maxOLS_testgoodp = ols('CMtnSNTL_Upcoming12hrSNOWFALL_gte3_in ~' + testgoodp_str, test_train_df[train_yrs_tt]).fit()\n",
    "  #print(testgoodp_str, maxOLS_testgoodp.rsquared_adj, test_thresh*0.01)\n",
    "  #print(maxOLS_testgoodp.rsquared_adj)\n",
    "  if maxOLS_testgoodp.rsquared_adj > rsq_adj:\n",
    "      rsq_adj = maxOLS_testgoodp.rsquared_adj\n",
    "      #print(maxOLS_testgoodp.rsquared_adj, test_thresh*0.01)\n",
    "      goodp_str = testgoodp_str\n",
    "      thresh = test_thresh*0.01\n",
    "      #print(thresh, goodp_str)\n",
    "\n",
    "    \n",
    "print(\"\\n best p value threshold for feature elimination is:\" + str(thresh))\n",
    "maxOLS_goodp = ols('CMtnSNTL_Upcoming12hrSNOWFALL_gte3_in ~' + goodp_str, test_train_df[train_yrs_tt]).fit() \n",
    "print(maxOLS_goodp.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doesn't like any improvement can be made**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make snowfall predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "actual_snf = test_train_df[test_yrs_tt]['CMtnSNTL_Upcoming12hrSNOWFALL_gte3_in']\n",
    "\n",
    "predict_snf = maxOLS_goodp.predict(test_train_df[test_yrs_tt])\n",
    "print(len(actual_snf))\n",
    "rows = zip(actual_snf, predict_snf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write both actual and predicted snowfall values to csv file for future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(r'C:\\Users\\RAPP\\Documents\\Capstone\\Analysis Notebooks\\model_predictions\\A0-SFC_OLS.csv', \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in rows:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
