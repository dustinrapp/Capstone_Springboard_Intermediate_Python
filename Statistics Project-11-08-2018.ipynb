{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project: Capstone Project - Inferential Statistics 2 - 6 Hours\n",
    "\n",
    "At this point, you have obtained the data set for your Capstone project, cleaned and wrangled it into a form that's ready for analysis. It's now time to apply the inferential statistics techniques you have learned to explore the data. For example, are there variables that are particularly significant in terms of explaining the answer to your project question? Are there strong correlations between pairs of independent variables, or between an independent and a dependent variable? Submission: Write a short report (1-2 pages) on the inferential statistics steps you performed and your findings. Check this report into your github and submit a link to it. Eventually, this report can be incorporated into your Milestone report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import necessary modules and the ASOS/SNOTEL dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dtb\n",
    "import os\n",
    "from glob import glob\n",
    "import datetime as dt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     TOBS.I-1 (degC)   SNWD.I-1 (in)   Temperature_degC  \\\n",
      "Date_Time                                                                 \n",
      "2006-01-01 01:00:00              -2.8            43.0              -1.0   \n",
      "2006-01-01 02:00:00              -2.9            43.0              -3.0   \n",
      "2006-01-01 03:00:00              -3.3            43.0              -4.0   \n",
      "2006-01-01 04:00:00              -3.2            43.0              -4.0   \n",
      "2006-01-01 05:00:00              -3.2            43.0              -5.0   \n",
      "\n",
      "                     Dewpoint_degC  Pressure_hp  WindDirection_deg  \\\n",
      "Date_Time                                                            \n",
      "2006-01-01 01:00:00           -7.0          NaN              220.0   \n",
      "2006-01-01 02:00:00           -8.0          NaN              230.0   \n",
      "2006-01-01 03:00:00           -8.0          NaN              230.0   \n",
      "2006-01-01 04:00:00           -9.0          NaN              240.0   \n",
      "2006-01-01 05:00:00           -8.0          NaN              210.0   \n",
      "\n",
      "                     WindSpeed_m/s  CloudCover  1hr_Precipitation_mm  \\\n",
      "Date_Time                                                              \n",
      "2006-01-01 01:00:00            7.7         NaN                   NaN   \n",
      "2006-01-01 02:00:00            5.1         NaN                   NaN   \n",
      "2006-01-01 03:00:00            3.6         NaN                   NaN   \n",
      "2006-01-01 04:00:00            6.2         NaN                   NaN   \n",
      "2006-01-01 05:00:00            6.2         NaN                   NaN   \n",
      "\n",
      "                     6hr_Precipitation_mm  LXV_Pressure_hp  \n",
      "Date_Time                                                   \n",
      "2006-01-01 01:00:00                   NaN            998.1  \n",
      "2006-01-01 02:00:00                   NaN            998.5  \n",
      "2006-01-01 03:00:00                   NaN            997.5  \n",
      "2006-01-01 04:00:00                   NaN            997.7  \n",
      "2006-01-01 05:00:00                   NaN            995.9  \n"
     ]
    }
   ],
   "source": [
    "data = [pd.read_csv('asos_snotel_inter_clean_df.dat', parse_dates = True, index_col = 'Date_Time')]\n",
    "asos_snotel_df= pd.concat(data)\n",
    "\n",
    "asos_snotel_df = asos_snotel_df.interpolate(limit=3)\n",
    "\n",
    "print(asos_snotel_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dataset which calculates the delta 12-HR snowdepth and 12-HR snowfall columns.  The delta 12-HR snowdepth contains the raw differences between snowdepth observations every 12 hours.  The 12-hr snowfall column will only include observations greater then or equal to 3 inches.  This will be useful for as snowfall is an important dependent variable **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    7835.000000\n",
      "mean       -0.001056\n",
      "std         1.676344\n",
      "min       -14.333333\n",
      "25%        -1.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max        18.000000\n",
      "Name: 12hr-delta_SNWD_in, dtype: float64\n",
      "count    343.000000\n",
      "mean       4.376024\n",
      "std        2.096673\n",
      "min        3.000000\n",
      "25%        3.000000\n",
      "50%        4.000000\n",
      "75%        5.000000\n",
      "max       18.000000\n",
      "Name: 12hr-SNOWFALL_in, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEyCAYAAADeAVWKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGLZJREFUeJzt3X+Q3PV93/HnWwjImKsl25grxQeS04TCoCBb1xsah3BHPKlPM5FrG7tlGFsd02oQtMUZO43tZEjalBnXLrShLkqT4FpuVeRE4Fohp8HU5vjRAdQTIzioiImLfhAoOJMKc2YCI/TuH/tVehKn27377H73dvV8zNzs3ne/u583L75z99J3f1xkJpIkSVqcZd0eQJIkqZdZpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgosr3Oxs88+O1etWtXRNX784x9z1llndXQNHc/M62Xe9TLvepl3vcx7fnv27PnzzHx3s/1qLVOrVq1iamqqo2tMTk4yOjra0TV0PDOvl3nXy7zrZd71Mu/5RcSBVvbzaT5JkqQClilJkqQClilJkqQClilJkqQClilJkqQClilJkqQClilJkqQCTctURAxFxP0RsS8ino6IG6vtvxURT0bE3oj4TkT8jc6P279u33t7t0eQJEmL0MqZqSPAZzPzIuAy4IaIuBj4Smb+TGauBe4BburgnK05tJvzD+yAQ7u7PcmCbXliS7dHkCRJi9C0TGXmi5n5eHX9VWAfcF5m/mjWbmcB2ZkRW3RoN2zdwOrntsHWDT1ZqCRJUu+JzNY7UESsAh4ELsnMH0XEzcCngFeAscz84Rz32QRsAhgcHFy3ffv2Noz9Vucf2MHq57YRHOUoy9i/+hoOXnBVR9Zql4nDE+x6Zddbto+vGGf9yvVdmGhxZmZmGBgY6PYYpwzzrpd518u862Xe8xsbG9uTmcPN9mu5TEXEAPAAcHNm3n3CbV8AfiIzf2O+xxgeHs6O/W2+6szU0SOvs2z5mbBxJwyNdGatDlizdQ3TG6e7Pcai+Led6mXe9TLvepl3vcx7fhHRUplq6d18EXE6cBew7cQiVfmvwMcWNmKbDY3Axp3sX31NzxUpSZLUu1p5N18AdwD7MvPWWdt/atZuG4Bn2j/eAg2NNJ7a68EitfnSzd0eQZIkLcLyFvb5APBJYDoi9lbbvghcGxEXAkeBA8B1nRnx1HD92uu7PYIkSVqEpmUqMx8GYo6bJto/jiRJUm/xE9AlSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKWKYkSZIKNC1TETEUEfdHxL6IeDoibqy2fyUinomIJyPiWxGxsvPjSpIkLS2tnJk6Anw2My8CLgNuiIiLgfuASzLzZ4DvA1/o3JiSJElLU9MylZkvZubj1fVXgX3AeZn5ncw8Uu32KPCezo0pSZK0NC3oNVMRsQp4H/DYCTd9GtjVnpEkSZJ6R2RmaztGDAAPADdn5t2ztv8aMAx8NOd4sIjYBGwCGBwcXLd9+/Z2zH1SMzMzDAwMdHQNHc/M62Xe9TLvepl3vcx7fmNjY3syc7jZfi2VqYg4HbgHuDczb521fSNwHfALmflas8cZHh7OqamppuuVmJycZHR0tKNr6HhmXi/zrpd518u862Xe84uIlsrU8hYeKIA7gH0nFKkPAb8KXNFKkZIkSepHTcsU8AHgk8B0ROyttn0RuA04E7iv0bd4NDOv68iUkiRJS1TTMpWZDwMxx00T7R9HkiSpt/gJ6JIkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQUsU5IkSQWalqmIGIqI+yNiX0Q8HRE3Vts/Xn1/NCKGOz+qJEnS0tPKmakjwGcz8yLgMuCGiLgYeAr4KPBgB+dbsInDE90e4ZTTq5nfvvf2bo8gSeoDTctUZr6YmY9X118F9gHnZea+zPyTTg+4ULte2dXtERbu0G546JbGZa85tLuReQ/OvuWJLd0eQZLUBxb0mqmIWAW8D3isE8Ockg7thq0b4Hs3Ny57qZQcmx16b3ZJktokMrO1HSMGgAeAmzPz7lnbJ4HPZebUSe63CdgEMDg4uG779u2lM7/FxOGJOc9Ija8YZ/3K9W1fr53OP7CD1c9tIzjKUZaxf/U1HLzgqm6P1VSvZt6rc882MzPDwMBAt8c4ZZh3vcy7XuY9v7GxsT2Z2fR14S2VqYg4HbgHuDczbz3htknmKVOzDQ8P59RU092KrNm6humN0x1do62Ond158w047QzYuBOGRro9VWuq2dcMvZvpQz/srdnpwWOlMjk5yejoaLfHOGWYd73Mu17mPb+IaKlMLW/hgQK4A9h3YpFSGwyNNErI/odg1eU9VUb+avbvXdtzRUqSpHZpWqaADwCfBKYjYm+17YvAmcC/B94N/HFE7M3Mv9uZMVs3vmK82yMs3NBI7xaRoZFG5j04/+ZLN3d7BElSH2hapjLzYSBOcvO32jtOuV553Us/6dXMr197fbdHkCT1AT8BXZIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqYBlSpIkqUDTMhURQxFxf0Tsi4inI+LGavs7I+K+iHi2unxH58eVNHF4otsjSJJmaeXM1BHgs5l5EXAZcENEXAx8HvhuZv4U8N3qe6k3HNoND93SuOwxu17Z1e0RJEmzLG+2Q2a+CLxYXX81IvYB5wEfBkar3bYCk8CvdmRKqZ0O7YatG+DNN+C0M2DjThga6fZUkqQeFZnZ+s4Rq4AHgUuAg5m5ctZt/zcz3/JUX0RsAjYBDA4Ortu+fXvhyPObmZlhYGCgo2voeL2W+fkHdrD6uW0ERznKMvavvoaDF1zV7bHmNXF4Ys4zUuMrxlm/cn0XJjp19Nrx3evMu17mPb+xsbE9mTncbL+Wy1REDAAPADdn5t0RcbiVMjXb8PBwTk1NtbTeYk1OTjI6OtrRNXS8nsu8x89Mrdm6humN090e45TRc8d3jzPvepn3/CKipTLV9Gm+6sFOB+4CtmXm3dXmlyLi3Mx8MSLOBV5e/LhSjYZGGgVq/0Ow6vKeKlKSpKWnaZmKiADuAPZl5q2zbtoJbAS+VF1+uyMTSp0wNNKzJWp8xXi3R5AkzdLKmakPAJ8EpiNib7XtizRK1B9ExLXAQeDjnRlR0my+RkqSlpZW3s33MBAnufkX2juOJElSb/ET0CVJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgpYpiRJkgo0LVMR8bWIeDkinpq17dKIeCQipiPijyLi7Z0dU1Kvu33v7d0eQeoYj+/6LaXMWzkz9XXgQyds+33g85m5BvgW8CttnkvSXA7t5vwDO+DQ7m5PsmBbntjS7RG01Hl816uH84allXnTMpWZDwJ/ccLmC4EHq+v3AR9r81ySTnRoN2zdwOrntsHWDT37A1Cak8d3vcy7rZYv8n5PARuAbwMfB4ZOtmNEbAI2AQwODjI5ObnIJVszMzPT8TV0PDOvx/kHdrD6yOsERzl65HX2f+8bHLzgtW6PNa+JwxPsemXXX32/ZusaAMZXjLN+5fpujbUgHt/18PiuVy/mDUs388jM5jtFrALuycxLqu//FnAb8C5gJ/DPMvNdzR5neHg4p6amSuZtanJyktHR0Y6uoeOZeU2qf0kePfI6y5afCRt3wtBIt6dq2Zqta5jeON3tMRbM47smHt/16vG8oZ7MI2JPZg43229R7+bLzGcy8xczcx1wJ/CDxTyOpAUYGoGNO9m/+pqe/MEnzcvju17m3VaLepovIs7JzJcjYhnw68DvtHcsSXMaGuHgBa/x3h78wbf50s3dHkFLncd3vXo4b1hambfy0Qh3Ao8AF0bE8xFxLXB1RHwfeAZ4AfhPnR1TUq+7fu313R5B6hiP7/otpcybnpnKzKtPctNvt3kWSZKknuMnoEuSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBVoWqYi4msR8XJEPDVr29qIeDQi9kbEVESMdHZMSdJC3L739m6PoB4wcXii2yP0hVbOTH0d+NAJ274M/IvMXAvcVH0vSf3l0G7OP7ADDu3u9iQLtuWJLd0e4dRxaDc8dEtPHie7XtnV7RH6wvJmO2TmgxGx6sTNwNur6yuAF9o7liR12aHdsHUDq4+8Dlt3wMadMORJeJ2gOk548w047QyPk1NUZGbznRpl6p7MvKT6/iLgXiBonN362cw8cJL7bgI2AQwODq7bvn17WwY/mZmZGQYGBjq6ho5n5vUy73qcf2AHq5/bRnCUoyxj/+prOHjBVd0ea14ThyfmPNMwvmKc9SvXd2Giheu149vjpL+NjY3tyczhZvsttkzdBjyQmXdFxCeATZn5wWaPMzw8nFNTU03XKzE5Ocno6GhH19DxzLxe5l2T6ozD0SOvs2z5mT13xmHN1jVMb5zu9hgL1nPHd4+fmerV46QuEdFSmWr6NN9JbARurK7/IfD7i3wcSVqahkZg4072f+8bvPfKT/XUL0jVqDpO2P8QrLrc4+QUtdgy9QJwBTAJXAk8266BJGnJGBrh4AWv8d4e/AW5+dLN3R7h1DE00rMlanzFeLdH6AtNy1RE3AmMAmdHxPPAbwD/GPjtiFgO/CXVa6IkSUvD9Wuv7/YI6gG+Rqo9Wnk339UnuWldm2eRJEnqOX4CuiRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUgHLlCRJUoGmZSoivhYRL0fEU7O2fTMi9lZf+yNib2fHlKTumDg80e0RTinmrV7UypmprwMfmr0hM/9+Zq7NzLXAXcDdHZhNUr84tBseuqVx2WN2vbKr2yMsnHlLtVrebIfMfDAiVs11W0QE8AngyvaOJalvHNoNWzfAm2/AaWfAxp0wNNLtqfqXeUu1i8xsvlOjTN2TmZecsP3ngVszc3ie+24CNgEMDg6u2759e8m8Tc3MzDAwMNDRNXQ8M69Xr+V9/oEdrH5uG8FRjrKM/auv4eAFV3V7rHlNHJ6Y8wzJ+Ipx1q9c34WJWmfeWohe+3lSt7GxsT3zdZxjSsvUFuBPM/OWVoYaHh7OqampVnZdtMnJSUZHRzu6ho5n5vXqubx7/EzJmq1rmN443e0xWmfeWoCe+3lSs4hoqUw1fZpvngWWAx8F1i32MSSdAoZGGr/Q9z8Eqy7vqV/sPcm8pdotukwBHwSeyczn2zWMpD41NNKzv9THV4x3e4SFM2+pVq18NMKdwCPAhRHxfERcW930D4A7OzmcJHWbr9mpl3mrF7Xybr6rT7L9H7Z9GkmSpB7jJ6BLkiQVsExJkiQVsExJkiQVsExJkiQVsExJkiQVsExJkiQVsExJkiQVaOlv87VtsYgfAgc6vMzZwJ93eA0dz8zrZd71Mu96mXe9zHt+F2Tmu5vtVGuZqkNETLXyRwnVPmZeL/Oul3nXy7zrZd7t4dN8kiRJBSxTkiRJBfqxTP1utwc4BZl5vcy7XuZdL/Oul3m3Qd+9ZkqSJKlO/XhmSpIkqTaWKUmSpAIdL1MRMRQR90fEvoh4OiJurLa/MyLui4hnq8t3VNsjIm6LiD+NiCcj4v2zHuvL1WPsq/aJOdZ7V7XeTER8ddb2t0XEH0fEM9VjfGmemddFxHQ1w1vWiYjPRURGxNntyKid+inviPjNiPiziNhbfa1vZ1bt0k+ZV7f904j4k+oxvtyunNqln/KOiG/OOr73R8TedmbVDn2W99qIeLTKeyoiRtqZVTv0Wd6XRsQj1W1/FBFvb2dWS0pmdvQLOBd4f3X9rwHfBy4Gvgx8vtr+eeBfV9fXA7uAAC4DHqu2/yzwP4DTqq9HgNE51jsL+DngOuCrs7a/DRirrp8BPASMn2Tm3cDfqWbYNXs/YAi4l8aHj57d6fxO5byB3wQ+1+1MT7HMx4D/DpxZfX9Ot/Pt57xP2OcW4KZu59vPeQPfmXV9PTDZ7Xz7PO//CVxRXf808FvdzrdTXx0/M5WZL2bm49X1V4F9wHnAh4Gt1W5bgb9XXf8w8I1seBRYGRHnAgn8BI3/qWcCpwMvzbHejzPzYeAvT9j+WmbeX11/A3gceM+J96/WentmPpKNI+Abs2YD+LfAP6/mWXL6MO8lr88y3wx8KTNfrx7n5UVE0lF9lvexfQL4BHDnAuPouD7LO4FjZ0dWAC8sMI6O67O8LwQerK7fB3xsgXH0jFpfMxURq4D3AY8Bg5n5IjQOHuCcarfzgEOz7vY8cF5mPgLcD7xYfd2bmfsWOcdK4JeA785x83nVmsetX91vA/BnmfnEYtatW6/nXfkn1anrrx07rb2U9UHmPw1cHhGPRcQDEfG3F7N+Xfog72MuB17KzGcXs35d+iDvzwBfiYhDwL8BvrCY9evSB3k/BWyorn+cxjM7fam2MhURA8BdwGcy80fz7TrHtoyIvwlcRKMZnwdcGRE/v4g5ltP4199tmfm/F7D+24BfA25a6Jrd0Ot5V5dbgJ8E1tL4YXDLQtevU59kvhx4B42nC34F+IO5XmexFPRJ3sdczRI8KzVbn+S9GfjlzBwCfhm4Y6Hr16VP8v40cENE7KHxlOUbC12/V9RSpiLidBoHxbbMvLva/FJ1evDYacJjTyc8z/Ht9T00TsV+BHg0M2cyc4bG87KXRcRH4v+/gLOVvy/0u8CzmfnvqrVPm3X/f1mtP/tU5rH1fxJYDTwREfur7Y9HxF9fWBqd1yd5k5kvZeabmXkU+D1gyb1Y9Jh+yby67e7qKYPdwFEafwh1SemjvI/9svoo8M2FZFCnPsp7I3Bs/j9kif5M6Ze8M/OZzPzFzFxHo5D9YKFZ9Io63s0XNNr/vsy8ddZNO2kc2FSX3561/VPRcBnwSnVK8yBwRUQsrw60K6rH/FZmrq2+pprM8q9oPE/+mWPbql/Wx+5/U7XWqxFxWTX7p4BvZ+Z0Zp6TmasycxWNA+j9mfl/igJqs37Ju7r/ubMe7iM0ThkvOf2UOfDfgCurx/ppGq+3WFJ/Ub7P8gb4IPBMZj7PEtRneb9QrQuN43zJPa3aT3lHxDnV5TLg14HfWXwyS1x2/p0JP0fjlN+TwN7qaz3wLhrPvz5bXb6z2j+A/0CjwU4Dw9X204D/SOPFeP8LuHWeNfcDfwHM0Cg9F9Noy1nd/9gc/+gk9x+m8Yv7B8BXofFJ8XOssRTfzdc3eQP/uZrpSRo/MM7tdr6nQOZnAP+luu1x4Mpu59vPeVe3fR24rtu5ngp5V/8te4AnaLwOaV238+3zvG+k8W7E7wNfYo7fpf3y5Z+TkSRJKuAnoEuSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBWwTEmSJBX4f5tyANzIRuhlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "#Calculate 12-snowfall column by finding difference between 12-hr snow depth observations \n",
    "asos_snotel_df['12hr_SNWD_in'] = asos_snotel_df['SNWD.I-1 (in) '].resample('12H').last()\n",
    "asos_snotel_df['12hr-delta_SNWD_in'] = asos_snotel_df['12hr_SNWD_in']-asos_snotel_df['12hr_SNWD_in'].shift(+12)\n",
    "asos_snotel_df['12hr-SNOWFALL_in'] = asos_snotel_df['12hr-delta_SNWD_in'][asos_snotel_df['12hr-delta_SNWD_in']>=3]\n",
    "\n",
    "print(asos_snotel_df['12hr-delta_SNWD_in'].describe())\n",
    "print(asos_snotel_df['12hr-SNOWFALL_in'].describe())\n",
    "\n",
    "plt.plot(asos_snotel_df['12hr-SNOWFALL_in']['12-04-2008':'12-09-2008'], marker = 'x')\n",
    "plt.plot(asos_snotel_df['12hr_SNWD_in']['12-04-2008':'12-09-2008'].shift(-12), marker = '.')\n",
    "plt.plot(asos_snotel_df['12hr_SNWD_in']['12-04-2008':'12-09-2008'], marker = '+')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'12-hr_ max_1-hr-dLXV_Pressure_hp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\rapp\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3062\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3063\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '12-hr_ max_1-hr-dLXV_Pressure_hp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-cea5b1e48b45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0masos_snotel_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'12-hr_max_3-hr-dLXV_Pressure_hp'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masos_snotel_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'3-hr-dLXV_Pressure_hp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'12H'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0masos_snotel_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'12-hr_min_3-hr-dLXV_Pressure_hp'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masos_snotel_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'3-hr-dLXV_Pressure_hp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'12H'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masos_snotel_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'12-hr_ max_1-hr-dLXV_Pressure_hp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\rapp\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2683\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2685\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rapp\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2690\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2692\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rapp\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2486\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rapp\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rapp\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3063\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3065\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '12-hr_ max_1-hr-dLXV_Pressure_hp'"
     ]
    }
   ],
   "source": [
    "asos_snotel_df['1-hr-dLXV_Pressure_hp'] = asos_snotel_df['LXV_Pressure_hp'].shift(+12)-asos_snotel_df['LXV_Pressure_hp'].shift(+13)\n",
    "asos_snotel_df['3-hr-dLXV_Pressure_hp'] = asos_snotel_df['LXV_Pressure_hp'].shift(+12)-asos_snotel_df['LXV_Pressure_hp'].shift(+15)\n",
    "asos_snotel_df['12-hr_max_1-hr-dLXV_Pressure_hp'] = asos_snotel_df['1-hr-dLXV_Pressure_hp'].resample('12H').max()\n",
    "asos_snotel_df['12-hr_min_1-hr-dLXV_Pressure_hp'] = asos_snotel_df['1-hr-dLXV_Pressure_hp'].resample('12H').min()\n",
    "asos_snotel_df['12-hr_max_3-hr-dLXV_Pressure_hp'] = asos_snotel_df['3-hr-dLXV_Pressure_hp'].resample('12H').max()\n",
    "asos_snotel_df['12-hr_min_3-hr-dLXV_Pressure_hp'] = asos_snotel_df['3-hr-dLXV_Pressure_hp'].resample('12H').min()\n",
    "print(asos_snotel_df['12-hr_ max_1-hr-dLXV_Pressure_hp'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do some quick timeseries plots to visually see the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = None\n",
    "keys = ['TOBS.I-1 (degC) ','Temperature_degC', 'Dewpoint_degC', 'WindDirection_deg', 'WindSpeed_m/s', 'CloudCover', 'SNWD.I-1 (in) ', 'LXV_Pressure_hp', '12hr-delta_SNWD_in', '12hr-SNOWFALL_in']\n",
    "\n",
    "fig = plt.figure(figsize=(50,75))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.1)\n",
    "for k in range(len(keys)):\n",
    "    ax = plt.subplot(12, 1, k+1)\n",
    "    asos_snotel_df[keys[k]]['2005':'2017'].plot(linestyle='None', ax = ax, marker = \".\", markersize = 1)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(keys[k])\n",
    "    \n",
    "    plt.title(\"Timeseries of \" + keys[k])\n",
    " \n",
    "    plt.grid()\n",
    "    plt.axis('tight')\n",
    "  \n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** &#8657; Some notes:  \n",
    "There is a a lot of missing data for year 2011 and 2016 - this should be kept in mind as it could skew some our analyeses slightly  \n",
    "Cloud Cover - something strange happens during year 2013 - only values from 0-4 get reported.  Again, this should be taken into account. Perhaps remove these years altogether for any Cloud Cover analysis **\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Check for Normality using NormTest  \n",
    "**Normality is an important prequsisite for application of frequentist tests.  Here, we will use SciPy's normtest function, which tests the ypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "from scipy.stats import mode\n",
    "keys = ['TOBS.I-1 (degC) ','Temperature_degC', 'Dewpoint_degC', 'WindDirection_deg', 'WindSpeed_m/s', 'CloudCover', 'SNWD.I-1 (in) ', 'LXV_Pressure_hp', '12hr-delta_SNWD_in',  '12hr-SNOWFALL_in']\n",
    "years = ['2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(25,30))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.2)\n",
    "for k in range(len(keys)):\n",
    "    ax = plt.subplot(5, 2, k+1)\n",
    "    \n",
    "    xx_df1 = asos_snotel_df[keys[k]][(asos_snotel_df[keys[k]].index.month >= 11) & \\\n",
    "                                                (asos_snotel_df[keys[k]].index.year == int(years[k]))].resample('12H').apply(lambda x: mode(x)[0][0]) #.reset_index()\n",
    "    xx_df2 = asos_snotel_df[keys[k]][(asos_snotel_df[keys[k]].index.month <=  4) & \\\n",
    "                                               (asos_snotel_df[keys[k]].index.year == int(years[k])+1)].resample('12H').apply(lambda x: mode(x)[0][0])  #.resample('12H').mid()\n",
    "                                                 \n",
    "                                              #   wd_df1 = bin_wd_df2['WindDirection_deg'][(bin_wd_df2['WindDirection_deg'].index.month >= 11) & \\\n",
    "                                               # (bin_wd_df2['WindDirection_deg'].index.year == int(years[k]))].resample('12H').apply(lambda x: mode(x)[0][0])\n",
    "    \n",
    "    xx_df = pd.concat([xx_df1, xx_df2])\n",
    "    \n",
    "    norm = stats.normaltest( asos_snotel_df[keys[k]].dropna())\n",
    "    x = pd.Series(asos_snotel_df[keys[k]].dropna(), name=keys[k])\n",
    "    ax = sns.distplot(x, norm_hist = True, bins = 10)\n",
    "    plt.annotate(str(norm),\n",
    "                 xy=(0.5, 1.01), xycoords='axes fraction', fontsize=10)\n",
    "                                      \n",
    "    \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "## Check to see if there is linear relationship between meteorological variables and snowfall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First calculate 12-snowfall column by finding difference between 12-hr snow depth observations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "#Calculate 12-snowfall column by finding difference between 12-hr snow depth observations \n",
    "asos_snotel_df['12hr_SNWD_in'] = asos_snotel_df['SNWD.I-1 (in) '].resample('12H').last()\n",
    "asos_snotel_df['12hr-SNOWFALL_in'] = asos_snotel_df['12hr_SNWD_in']-asos_snotel_df['12hr_SNWD_in'].shift(+12)\n",
    "\n",
    "\n",
    "print(asos_snotel_df['12hr-SNOWFALL_in'].describe())\n",
    "\n",
    "#print(asos_snotel_df['12hr-SNOWFALL_in']['12-16-2009':'12-19-2009'].head(500).dropna())\n",
    "#print(asos_snotel_df['12hr-SNOWFALL_in']['12-16-2009':'12-19-2009'].shift(-12).head(500).dropna())\n",
    "#print(asos_snotel_df['12hr_SNWD_in']['12-16-2009':'12-19-2009'].head(500).dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make a quick plot to make sure the snowfall difference calc is doing what we think it is**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(asos_snotel_df['12hr-SNOWFALL_in']['12-04-2008':'12-09-2008'], marker = 'x')\n",
    "plt.plot(asos_snotel_df['12hr_SNWD_in']['12-04-2008':'12-09-2008'].shift(-12), marker = '.')\n",
    "plt.plot(asos_snotel_df['12hr_SNWD_in']['12-04-2008':'12-09-2008'], marker = '+')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Linear Regression plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, linregress\n",
    "\n",
    "fig = plt.figure(figsize=(20,25))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.1)\n",
    "yy = None\n",
    "yy = (asos_snotel_df['12hr-SNOWFALL_in']>=3)\n",
    "snf_df = asos_snotel_df['12hr-SNOWFALL_in'][yy]\n",
    "\n",
    "#keys = ['TOBS.I-1 (degC) ', 'Dewpoint_degC', 'WindDirection_deg', 'WindSpeed_m/s', 'CloudCover', 'LAX_Pressure_hp' ]\n",
    "\n",
    "for k in range(len(keys)):\n",
    "    xx_df = None\n",
    "    plt.subplot(4,2,k+1)\n",
    "\n",
    "    xx_df = asos_snotel_df[keys[k]].resample('12H').max()\n",
    "\n",
    "#print(ws_df, snf_df)\n",
    "\n",
    "#snf_ws_df = pd.merge(sn, asos_filled_df, on='Date_Time', how='outer')\n",
    "    idx = np.isfinite(xx_df) & np.isfinite(snf_df)\n",
    "    sns.regplot(xx_df[idx], snf_df[idx])\n",
    "    \n",
    "    pearson, pv = pearsonr(xx_df[idx], snf_df[idx])\n",
    "    #print(linregress(xx_df[idx], snf_df[idx]))\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(xx_df[idx], snf_df[idx])\n",
    "    \n",
    "    \n",
    "    #plt.text(5,5,r'$\\cos(2 \\pi t) \\exp(-t)$')\n",
    "    #plt.text(0.5,0.5,'This is awesome! \\n test' ,  bbox=dict(facecolor='red', alpha=0.5), transform=ax.transAxes)\n",
    "    plt.annotate(' slope: ' + str(round(slope,3)) +\n",
    "                 '\\n intercept: ' + str(round(intercept,3)) + \n",
    "                 '\\n R value: ' + str(round(r_value,3)) +  \n",
    "                 '\\n p value: ' + str(round(p_value,3)) + \n",
    "                 '\\n Std error: ' + str(round(std_err,3)) +\n",
    "                 '\\n Pearson: ' + str(round(pearson,3)), \\\n",
    "                 xy=(0.83, 0.72), xycoords='axes fraction', fontsize=10)\n",
    "                                      \n",
    "#    print()\n",
    "#    print(str(keys[k]))\n",
    "#    print('slope: '+ str(slope))\n",
    "#    print('intercept:')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It does not appear that there is a nice linear relationship between temperature and snowfall.  There does appear to be somewhat of a relationshop with Dewpoint, so this will be investigated further. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "## Is there a linear relationship between ASOS temperatures and SNOTEL temperatures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "asos_temp_df=asos_snotel_df['Temperature_degC']\n",
    "snotel_temp_df = asos_snotel_df['TOBS.I-1 (degC) ']\n",
    "\n",
    "\n",
    "\n",
    "idx = np.isfinite(asos_temp_df) & np.isfinite(snotel_temp_df)\n",
    "\n",
    "# Plot the snowfall vs temperature\n",
    "_ = plt.plot(snotel_temp_df[idx], asos_temp_df[idx], marker='.', linestyle='none')\n",
    "plt.margins(0.02)\n",
    "_ = plt.ylabel('ASOS Temperature (deg C)')\n",
    "_ = plt.xlabel('SNOTEL temperature (deg C)')\n",
    "_ = plt.xlim([-35, 25])\n",
    "_ = plt.ylim([-35, 25])\n",
    "\n",
    "\n",
    "# Perform a linear regression using np.polyfit(): a, b\n",
    "a, b = np.polyfit(snotel_temp_df[idx], asos_temp_df[idx], 1)\n",
    "\n",
    "# Print the results to the screen\n",
    "print('slope =', a)\n",
    "print('intercept =', b) \n",
    "\n",
    "print(a,b)\n",
    "\n",
    "# Make theoretical line to plot\n",
    "x = np.array([np.min(asos_temp_df[idx]),np.max(asos_temp_df[idx])])\n",
    "y = a * x + b\n",
    "_ = plt.plot(x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationship between Snowfall events and Meteorological Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To begin, all meteorological variables must be reasonably binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx1 = asos_snotel_df[(asos_snotel_df.index.month >= 11) &  (asos_snotel_df.index.month <=  4)]\n",
    "\n",
    "                                                 \n",
    "                                              #   wd_df1 = bin_wd_df2['WindDirection_deg'][(bin_wd_df2['WindDirection_deg'].index.month >= 11) & \\\n",
    "                                               # (bin_wd_df2['WindDirection_deg'].index.year == int(years[k]))].resample('12H').apply(lambda x: mode(x)[0][0])\n",
    "asos_snotel_winter_df = asos_snotel_df[xx1]\n",
    "\n",
    "print( asos_snotel_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bin each variable in a consistent format resampling every 12H**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "def bin_df_data(df, bin_ranges):  \n",
    "    binned_df = df.copy()\n",
    "    binned_df[:] = np.NaN\n",
    "    \n",
    "    for t in range(1, len(bin_ranges)):\n",
    "        binned_df[(df[:] >= bin_ranges[t-1]) & (df[:] < bin_ranges[t])] = (bin_ranges[t]+ bin_ranges[t-1])/2\n",
    "    \n",
    "    binned_df.columns = ['bin']\n",
    "    return binned_df\n",
    "\n",
    "#keys = ['Temperature_degC', 'Dewpoint_degC', 'TOBS.I-1 (degC) ']\n",
    "#temp_range = [-40, -35, -30, -25, -20, -15, -10, -5, 0, 5, 10]\n",
    "\n",
    "#Bin linear variables###############################################################\n",
    "temp_range = [-40, -38, -36, -34, -32, -30, -28, -26, -24, -22, -20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40 ]\n",
    "ws_range = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "bp_range = [9860, 9880, 9900, 9920, 9940, 9960, 9980, 10000, 10020, 10040, 10060, 10080, 10100, 10120, 10140, 10160, 10180, 10200, 10220, 10240, 10260, 10280, 10300, 10320, 10340, 10360, 10380, 10400]\n",
    "\n",
    "binned_12H_Temp = bin_df_data(asos_snotel_df['Temperature_degC'].resample('12H').mean(), temp_range)\n",
    "ASOStemp_bin_counts = binned_12H_Temp.groupby(binned_12H_Temp).size().reset_index(name='Counts')\n",
    "\n",
    "binned_12H_TOBS = bin_df_data(asos_snotel_df['TOBS.I-1 (degC) '].resample('12H').mean(), temp_range)\n",
    "SNOTELtemp_bin_counts = binned_12H_TOBS.groupby(binned_12H_TOBS).size().reset_index(name='Counts')\n",
    "\n",
    "binned_12H_DP = bin_df_data(asos_snotel_df['Dewpoint_degC'].resample('12H').mean(), temp_range)\n",
    "DP_bin_counts = binned_12H_DP.groupby(binned_12H_DP).size().reset_index(name= 'Counts')\n",
    "\n",
    "binned_12H_WS = bin_df_data(asos_snotel_df['WindSpeed_m/s'].resample('12H').mean(), ws_range)\n",
    "WS_bin_counts = binned_12H_WS.groupby(binned_12H_WS).size().reset_index(name='Counts')\n",
    "\n",
    "binned_12H_P = bin_df_data(asos_snotel_df['LXV_Pressure_hp'].resample('12H').mean(), bp_range)\n",
    "BP_bin_counts = binned_12H_P.groupby(binned_12H_P).size().reset_index(name='Counts')\n",
    "\n",
    "\n",
    "\n",
    "## Bin Wind Direction########################################\n",
    "bin_wd_df = pd.DataFrame()\n",
    "binned_WD =  asos_snotel_df['WindDirection_deg'].copy()\n",
    "\n",
    "binned_WD[(binned_WD >= 337.5) | (binned_WD < 22.5)] = 0\n",
    "binned_WD[(binned_WD >= 22.5) & (binned_WD < 67.5)] = 45\n",
    "binned_WD[(binned_WD >= 67.5) & (binned_WD < 112.5)] = 90\n",
    "binned_WD[(binned_WD >= 112.5) & (binned_WD < 157.5)] = 135\n",
    "binned_WD[(binned_WD >= 157.5) & (binned_WD < 202.5)] = 180\n",
    "binned_WD[(binned_WD >= 202.5) & (binned_WD < 247.5)] = 225\n",
    "binned_WD[(binned_WD >= 247.5) & (binned_WD < 292.5)] = 270\n",
    "binned_WD[(binned_WD >= 292.5) & (binned_WD< 337.5)] = 315\n",
    "\n",
    "binned_12H_WD = binned_WD.resample('12H').apply(lambda x: mode(x)[0])\n",
    "binned_12H_WD = pd.to_numeric(binned_12H_WD, errors='coerce')\n",
    "\n",
    "\n",
    "##Bin Snowfall########\n",
    "binned_SNF = asos_snotel_df['12hr-SNOWFALL_in'].copy()\n",
    "yy = (binned_SNF <3)\n",
    "binned_SNF[yy] = np.NaN\n",
    "\n",
    "binned_SNF[(binned_SNF >= 3.0) & (binned_SNF <5.5) ]= 4\n",
    "binned_SNF[(binned_SNF >= 5.5) & (binned_SNF< 7.5)] = 6\n",
    "binned_SNF[(binned_SNF >= 7.5) & (binned_SNF < 9.5)] = 8\n",
    "binned_SNF[(binned_SNF >= 9.5)] = 10\n",
    "\n",
    "binned_12H_SNF = binned_SNF.resample('12H').last()\n",
    "\n",
    "\n",
    "\n",
    "##Put all data in individual dataframe\n",
    "binned_df = None\n",
    "binned_df = binned_12H_SNF.to_frame().join(binned_12H_Temp.to_frame(), on = 'Date_Time', how= 'outer') \\\n",
    "                                     .join(binned_12H_TOBS.to_frame(), on = 'Date_Time', how= 'outer')  \\\n",
    "                                     .join(binned_12H_DP.to_frame(), on = 'Date_Time', how= 'outer')  \\\n",
    "                                     .join(binned_12H_WS.to_frame(), on = 'Date_Time', how= 'outer')  \\\n",
    "                                     .join(binned_12H_WD.to_frame(), on = 'Date_Time', how= 'outer')  \\\n",
    "                                     .join(binned_12H_P.to_frame(), on = 'Date_Time', how= 'outer')  \\\n",
    "\n",
    "#print(binned_12H_Temp.head())\n",
    "#print(binned_12H_TOBS.head())\n",
    "#print(binned_12H_DP.head())\n",
    "#print(binned_12H_WS.head())\n",
    "#print(binned_12H_WD.head())\n",
    "#print(binned_12H_P.head())\n",
    "#print(binned_12H_SNF.head())\n",
    "\n",
    "print(binned_df.head())\n",
    "\n",
    "\n",
    "#      ...: fig = plt.figure( figsize =( 6,6))      ...: fig.add_subplot( gs[ 1,: 2])      ...: fig.add_subplot( gs[ 0,: 2])\n",
    "\n",
    "\n",
    "#.hist(bin_temp_df['Temperature_degC'].dropna())\n",
    "#plt.hist(bin_temp_df['Temperature_degC'].dropna(), bins=temp_range)\n",
    "#plt.xlabel()\n",
    "#plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot variable vs counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize =(30,20)) \n",
    "fig.suptitle('Counts of Meteorological Variables by Value', fontsize=30)\n",
    "\n",
    "fig.add_subplot(421)\n",
    "sns.countplot(binned_df['Temperature_degC'])\n",
    "fig.add_subplot(422)\n",
    "sns.countplot(binned_df['TOBS.I-1 (degC) '])\n",
    "fig.add_subplot(423)\n",
    "sns.countplot(binned_df['Dewpoint_degC'])\n",
    "fig.add_subplot(424)\n",
    "sns.countplot(binned_df['WindSpeed_m/s'])\n",
    "fig.add_subplot(425)\n",
    "sns.countplot(binned_df['WindDirection_deg'])\n",
    "fig.add_subplot(426)\n",
    "sns.countplot(binned_df['LXV_Pressure_hp'])\n",
    "fig.add_subplot(427)\n",
    "sns.countplot(binned_df['12hr-SNOWFALL_in'])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot variable vs actual snowfall totals for each bin**  \n",
    "To do this, first add a column of actual snowfall totals to the bin dataframe to create a new dataframe for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add actual snowfall total column to binned_df\n",
    "SNF = asos_snotel_df['12hr-SNOWFALL_in'].copy()\n",
    "yy = (SNF <3)\n",
    "SNF[yy] = np.NaN\n",
    "\n",
    "df = binned_df.join(SNF.resample('12H').last(),on = 'Date_Time', how= 'outer', rsuffix = '_act')\n",
    "df_wk = binned_df.join(SNF.resample('w').sum(),on = 'Date_Time', how= 'outer', rsuffix = '_act')\n",
    "\n",
    "#df_wk = df.resample('w').mean()\n",
    "\n",
    "\n",
    "#Plot\n",
    "fig = plt.figure( figsize =(30,20)) \n",
    "fig.suptitle('Total Snowfall by Meteorological Variables and Value', fontsize=30)\n",
    "\n",
    "keys = ['TOBS.I-1 (degC) ','Temperature_degC', 'Dewpoint_degC', 'WindDirection_deg', 'WindSpeed_m/s', 'LXV_Pressure_hp']\n",
    "\n",
    "for k in range(len(keys)):\n",
    "  fig.add_subplot(4,2,k+1)\n",
    "  sns.barplot(df.groupby([keys[k]]).sum()['12hr-SNOWFALL_in_act'].index, df.groupby([keys[k]]).sum()['12hr-SNOWFALL_in_act'])\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure( figsize =(30,20))\n",
    "fig.suptitle('Total Snowfall by Meteorological Variables and Value (resampled by week)', fontsize=30)\n",
    "for k in range(len(keys)):\n",
    "  fig.add_subplot(4,2,k+1)\n",
    "  sns.barplot(df_wk.groupby([keys[k]]).last()['12hr-SNOWFALL_in_act'].index, df_wk.groupby([keys[k]]).last()['12hr-SNOWFALL_in_act'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot snowfall data resampled by week**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add actual snowfall total column to binned_df\n",
    "SNF = asos_snotel_df['12hr-SNOWFALL_in'].copy()\n",
    "yy = (SNF <3)\n",
    "SNF[yy] = np.NaN\n",
    "\n",
    "df = binned_df.join(SNF.resample('12H').last(),on = 'Date_Time', how= 'outer', rsuffix = '_act')\n",
    "\n",
    "\n",
    "#Plot\n",
    "fig = plt.figure( figsize =(30,5)) \n",
    "\n",
    "snf_df_count = df['12hr-SNOWFALL_in_act'].resample('w').count()\n",
    "snf_df_sum = df['12hr-SNOWFALL_in_act'].resample('w').sum()\n",
    "snf_df_mean = df['12hr-SNOWFALL_in_act'].resample('w').mean()\n",
    "\n",
    "\n",
    "fig = plt.figure( figsize =(30,5)) \n",
    "\n",
    "fig.add_subplot(1,3,1)\n",
    "plt.title('Count of Snowfall events by Week')\n",
    "sns.barplot(snf_df_count.index.week, snf_df_count)\n",
    "plt.xlabel('Week #')\n",
    "plt.ylabel('count')\n",
    "\n",
    "fig.add_subplot(1,3,2)\n",
    "plt.title('Sum of Snowfall events by Week')\n",
    "sns.barplot(snf_df_sum.index.week, snf_df_sum)\n",
    "plt.xlabel('Week #')\n",
    "plt.ylabel('Total Snowfall (in)')\n",
    "\n",
    "fig.add_subplot(1,3,3)\n",
    "plt.title('Mean Snowfall Totals by Week')\n",
    "sns.barplot(snf_df_mean.index.week, snf_df_mean)\n",
    "plt.xlabel('Week #')\n",
    "plt.ylabel('Mean Snowfall (in)')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##Using plt.bar \n",
    "fig = plt.figure( figsize =(30,5)) \n",
    "fig.add_subplot(1,3,1)\n",
    "plt.title('Count of Snowfall events by Week')\n",
    "plt.bar(snf_df_count.index.week, snf_df_count)\n",
    "plt.xlabel('Week #')\n",
    "plt.ylabel('count')\n",
    "\n",
    "fig.add_subplot(1,3,2)\n",
    "plt.title('Sum of Snowfall events by Week')\n",
    "plt.bar(snf_df_sum.index.week, snf_df_sum)\n",
    "plt.xlabel('Week #')\n",
    "plt.ylabel('Total Snowfall (in)')\n",
    "\n",
    "fig.add_subplot(1,3,3)\n",
    "plt.title('Mean Snowfall Totals by Week')\n",
    "plt.bar(snf_df_mean.index.week, snf_df_mean)\n",
    "plt.xlabel('Week #')\n",
    "plt.ylabel('Mean Snowfall (in)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot snowfall data by month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( figsize =(30,5)) \n",
    "\n",
    "snf_df_count = df['12hr-SNOWFALL_in_act'].resample('m').count()\n",
    "snf_df_sum = df['12hr-SNOWFALL_in_act'].resample('m').sum()\n",
    "snf_df_mean = df['12hr-SNOWFALL_in_act'].resample('m').mean()\n",
    "\n",
    "fig.add_subplot(1,3,1)\n",
    "plt.title('Count of Snowfall events by Month')\n",
    "sns.barplot(snf_df_count.index.month, snf_df_count)\n",
    "plt.xlabel('Month #')\n",
    "plt.ylabel('count')\n",
    "\n",
    "fig.add_subplot(1,3,2)\n",
    "plt.title('Sum of Snowfall Totals by Month')\n",
    "sns.barplot(snf_df_sum.index.month, snf_df_sum)\n",
    "plt.xlabel('Month #')\n",
    "plt.ylabel('count')\n",
    "\n",
    "fig.add_subplot(1,3,3)\n",
    "plt.title('Mean Snowfall Totals by Month')\n",
    "sns.barplot(snf_df_mean.index.month, snf_df_mean)\n",
    "plt.xlabel('Month #')\n",
    "plt.ylabel('Mean Snowfall (in)')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Using plt.bar\n",
    "fig = plt.figure( figsize =(30,5)) \n",
    "\n",
    "snf_df_count = df['12hr-SNOWFALL_in_act'].resample('m').count()\n",
    "snf_df_sum = df['12hr-SNOWFALL_in_act'].resample('m').sum()\n",
    "snf_df_mean = df['12hr-SNOWFALL_in_act'].resample('m').mean()\n",
    "\n",
    "fig.add_subplot(1,3,1)\n",
    "plt.title('Count of Snowfall events by Month')\n",
    "plt.bar(snf_df_count.index.month, snf_df_count)\n",
    "plt.xlabel('Month #')\n",
    "plt.ylabel('count')\n",
    "\n",
    "fig.add_subplot(1,3,2)\n",
    "plt.title('Sum of Snowfall Totals by Month')\n",
    "plt.bar(snf_df_sum.index.month, snf_df_sum)\n",
    "plt.xlabel('Month #')\n",
    "plt.ylabel('Total Snowfall (in)')\n",
    "\n",
    "fig.add_subplot(1,3,3)\n",
    "plt.title('Mean Snowfall Totals by Month')\n",
    "plt.bar(snf_df_mean.index.month, snf_df_mean)\n",
    "plt.xlabel('Month #')\n",
    "plt.ylabel('Mean Snowfall (in)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "def bin_df_data(df, bin_ranges):  \n",
    "    binned_df = df.copy()\n",
    "    binned_df[:] = np.NaN\n",
    "    \n",
    "    for t in range(1, len(bin_ranges)):\n",
    "        binned_df[(df[:] >= bin_ranges[t-1]) & (df[:] < bin_ranges[t])] = (bin_ranges[t]+ bin_ranges[t-1])/2\n",
    "    \n",
    "    binned_df.columns = ['bin']\n",
    "    return binned_df\n",
    "\n",
    "#keys = ['Temperature_degC', 'Dewpoint_degC', 'TOBS.I-1 (degC) ']\n",
    "#temp_range = [-40, -35, -30, -25, -20, -15, -10, -5, 0, 5, 10]\n",
    "\n",
    "#Bin linear variables###############################################################\n",
    "temp_range = [-40, -38, -36, -34, -32, -30, -28, -26, -24, -22, -20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40 ]\n",
    "ws_range = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "bp_range = [9860, 9880, 9900, 9920, 9940, 9960, 9980, 10000, 10020, 10040, 10060, 10080, 10100, 10120, 10140, 10160, 10180, 10200, 10220, 10240, 10260, 10280, 10300, 10320, 10340, 10360, 10380, 10400]\n",
    "\n",
    "binned_12H_Temp = bin_df_data(asos_snotel_df['Temperature_degC'].resample('w').mean(), temp_range)\n",
    "ASOStemp_bin_counts = binned_12H_Temp.groupby(binned_12H_Temp).size().reset_index(name='Counts')\n",
    "\n",
    "binned_12H_TOBS = bin_df_data(asos_snotel_df['TOBS.I-1 (degC) '].resample('1w').mean(), temp_range)\n",
    "SNOTELtemp_bin_counts = binned_12H_TOBS.groupby(binned_12H_TOBS).size().reset_index(name='Counts')\n",
    "\n",
    "binned_12H_DP = bin_df_data(asos_snotel_df['Dewpoint_degC'].resample('w').mean(), temp_range)\n",
    "DP_bin_counts = binned_12H_DP.groupby(binned_12H_DP).size().reset_index(name= 'Counts')\n",
    "\n",
    "binned_12H_WS = bin_df_data(asos_snotel_df['WindSpeed_m/s'].resample('w').mean(), ws_range)\n",
    "WS_bin_counts = binned_12H_WS.groupby(binned_12H_WS).size().reset_index(name='Counts')\n",
    "\n",
    "binned_12H_P = bin_df_data(asos_snotel_df['LXV_Pressure_hp'].resample('w').mean(), bp_range)\n",
    "BP_bin_counts = binned_12H_P.groupby(binned_12H_P).size().reset_index(name='Counts')\n",
    "\n",
    "\n",
    "\n",
    "## Bin Wind Direction########################################\n",
    "bin_wd_df = pd.DataFrame()\n",
    "binned_WD =  asos_snotel_df['WindDirection_deg'].copy()\n",
    "\n",
    "binned_WD[(binned_WD >= 337.5) | (binned_WD < 22.5)] = 0\n",
    "binned_WD[(binned_WD >= 22.5) & (binned_WD < 67.5)] = 45\n",
    "binned_WD[(binned_WD >= 67.5) & (binned_WD < 112.5)] = 90\n",
    "binned_WD[(binned_WD >= 112.5) & (binned_WD < 157.5)] = 135\n",
    "binned_WD[(binned_WD >= 157.5) & (binned_WD < 202.5)] = 180\n",
    "binned_WD[(binned_WD >= 202.5) & (binned_WD < 247.5)] = 225\n",
    "binned_WD[(binned_WD >= 247.5) & (binned_WD < 292.5)] = 270\n",
    "binned_WD[(binned_WD >= 292.5) & (binned_WD< 337.5)] = 315\n",
    "\n",
    "binned_12H_WD = binned_WD.resample('12H').apply(lambda x: mode(x)[0])\n",
    "binned_12H_WD = pd.to_numeric(binned_12H_WD, errors='coerce')\n",
    "\n",
    "\n",
    "##Bin Snowfall########\n",
    "binned_SNF = asos_snotel_df['12hr-SNOWFALL_in'].resample('w').mean().copy()\n",
    "yy = (binned_SNF <3)\n",
    "binned_SNF[yy] = np.NaN\n",
    "\n",
    "binned_SNF[(binned_SNF >= 3.0) & (binned_SNF <5.5) ]= 4\n",
    "binned_SNF[(binned_SNF >= 5.5) & (binned_SNF< 7.5)] = 6\n",
    "binned_SNF[(binned_SNF >= 7.5) & (binned_SNF < 9.5)] = 8\n",
    "binned_SNF[(binned_SNF >= 9.5)] = 10\n",
    "\n",
    "binned_12H_SNF = binned_SNF.resample('12H').last()\n",
    "\n",
    "\n",
    "\n",
    "##Put all data in individual dataframe\n",
    "wk_binned_df = None\n",
    "wk_binned_df = binned_12H_SNF.to_frame().join(binned_12H_Temp.to_frame(), on = 'Date_Time', how= 'outer') \\\n",
    "                                     .join(binned_12H_TOBS.to_frame(), on = 'Date_Time', how= 'outer')  \\\n",
    "                                     .join(binned_12H_DP.to_frame(), on = 'Date_Time', how= 'outer')  \\\n",
    "                                     .join(binned_12H_WS.to_frame(), on = 'Date_Time', how= 'outer')  \\\n",
    "                                     .join(binned_12H_WD.to_frame(), on = 'Date_Time', how= 'outer')  \\\n",
    "                                     .join(binned_12H_P.to_frame(), on = 'Date_Time', how= 'outer')  \\\n",
    "\n",
    "#print(binned_12H_Temp.head())\n",
    "#print(binned_12H_TOBS.head())\n",
    "#print(binned_12H_DP.head())\n",
    "#print(binned_12H_WS.head())\n",
    "#print(binned_12H_WD.head())\n",
    "#print(binned_12H_P.head())\n",
    "#print(binned_12H_SNF.head())\n",
    "\n",
    "print(wk_binned_df.head())\n",
    "\n",
    "\n",
    "#      ...: fig = plt.figure( figsize =( 6,6))      ...: fig.add_subplot( gs[ 1,: 2])      ...: fig.add_subplot( gs[ 0,: 2])\n",
    "\n",
    "\n",
    "#.hist(bin_temp_df['Temperature_degC'].dropna())\n",
    "#plt.hist(bin_temp_df['Temperature_degC'].dropna(), bins=temp_range)\n",
    "#plt.xlabel()\n",
    "#plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind Direction vs Snowfall Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot wind speed, wind direction and snowfall together on polar plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_df = None\n",
    "ws_df1 = None\n",
    "ws_df2 = None\n",
    "wd_df1 = None\n",
    "wd_df2 = None\n",
    "wd_df = None\n",
    "df = None\n",
    "df_all = None\n",
    "areas = None\n",
    "\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "years = ['2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017']\n",
    "\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(25,30))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.1)\n",
    "for k in range(len(years)):\n",
    "    #print(str(int(years[k])+1))\n",
    "    #plt.subplot(4, 3, k+1)\n",
    "    \n",
    "    wd_df1 = binned_df['WindDirection_deg'][(binned_df['WindDirection_deg'].index.month >= 11) & \\\n",
    "                                                (binned_df['WindDirection_deg'].index.year == int(years[k]))].resample('12H').apply(lambda x: mode(x)[0][0]) #.reset_index()\n",
    "    wd_df2 = binned_df['WindDirection_deg'][(binned_df['WindDirection_deg'].index.month <= 4) & \\\n",
    "                                               (binned_df['WindDirection_deg'].index.year == int(years[k])+1)].resample('12H').apply(lambda x: mode(x)[0][0])  #.resample('12H').mid()\n",
    "    \n",
    "    wd_df = pd.concat([wd_df1, wd_df2])\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    ws_df1 = binned_df['WindSpeed_m/s'][(binned_df['WindSpeed_m/s'].index.month >= 11) & \\\n",
    "                                                (binned_df['WindSpeed_m/s'].index.year == int(years[k]))].resample('12H').mean().round()  #reset_index()\n",
    "    ws_df2 = binned_df['WindSpeed_m/s'][(binned_df['WindSpeed_m/s'].index.month <= 4) & \\\n",
    "                                                (binned_df['WindSpeed_m/s'].index.year == int(years[k])+1)].resample('12H').mean().round()  #.resample('12H').mid()\n",
    "    \n",
    "    ws_df = pd.concat([ws_df1, ws_df2])\n",
    "    \n",
    "    \n",
    "    snf_rs1 = binned_df[(binned_df['12hr-SNOWFALL_in'].index.month >= 11) & (binned_df['12hr-SNOWFALL_in'].index.year == int(years[k]))]\n",
    "    snf_rs2 = binned_df[(binned_df['12hr-SNOWFALL_in'].index.month <= 4) & (binned_df['12hr-SNOWFALL_in'].index.year == int(years[k])+1)]\n",
    "    #snf_rs =snf_rs1.to_frame().join(snf_rs2.to_frame(), right_index=True, left_index=True,how='outer').resample('1H').interpolate(limit=12).resample('H', how = 'min')\n",
    "    snf_rs = pd.concat([snf_rs1, snf_rs2])\n",
    "    print(snf_rs)\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "    df1 = wd_df.to_frame().merge(ws_df.to_frame(), right_index=True, left_index=True,how='outer')\n",
    "    df = df1.merge(snf_rs, right_index=True, left_index=True,how='outer')\n",
    "\n",
    "    #df_all = pd.concat([df_all, df])\n",
    "   # print(df.head())\n",
    "\n",
    "    \n",
    "    areas = df.groupby(['WindDirection_deg', 'WindSpeed_m/s', '12hr-SNOWFALL_bin']).size().reset_index(name='counts')\n",
    " \n",
    " \n",
    "    ax = fig.add_subplot(4, 3, k+1, projection='polar')\n",
    "  \n",
    "    #ax.bar(df['WindDirection_deg'], df['12hr-SNOWFALL'], normed=True, bins=np.arange(3, 18, 3), opening=0.8, edgecolor='white')\n",
    "    #ax.scatter(df['WindDirection_deg'], df['12hr-SNOWFALL'])\n",
    "   \n",
    "    \n",
    "    #categories = np.unique(df['12hr-SNOWFALL_bin'])\n",
    "    #colors = np.linspace(0, 1, len(categories))\n",
    "    #colordict = dict(zip(categories, colors))\n",
    "    #df[\"Color\"] = df[catcol].apply(lambda x: colordict[x])\n",
    "    \n",
    "    #plt.scatter(x, y, s=areas * 3, alpha=0.5)\n",
    "    ax.scatter(np.radians(areas['WindDirection_deg']), areas['WindSpeed_m/s'], s = areas['counts']*100, c = areas['12hr-SNOWFALL_bin'], cmap='rainbow_r', vmin=3, vmax=10, alpha = 0.55)\n",
    "    #ax.bar(df['WindDirection_deg'], df['WindSpeed_m/s'])\n",
    "    #ax.contour(df['WindDirection_deg'], df['WindSpeed_m/s'], bins=np.arange(3, 18, 5), normed=True, lw=3)\n",
    "   #plt.ylabel(\"% of occurence\")\n",
    "    plt.title(\"Ski Season Snowfall by Wind Direction: \"+ str(int(years[k])-1) + \"-\"+ years[k])\n",
    "\n",
    "    \n",
    "   # ax.set_legend(title = 'Snowfall (inches)')\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "    #plt.scatter(areas['WindDirection_deg'][g1], areas['WindSpeed_m/s'][g1], s = areas['counts'][g1]*100, alpha = 0.25)\n",
    "    #plt.show()\n",
    "\n",
    "#print(df[df['12hr-SNOWFALL_bin'] != np.NaN])\n",
    "aa = df_all['12hr-SNOWFALL_bin'] >0\n",
    "print(aa)\n",
    "\n",
    "print(df_all[aa])\n",
    "\n",
    "\n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make a plot with no ski season dependence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_jitter(arr):\n",
    "    stdev = arr.max()/100.\n",
    "    return arr + np.random.randn(len(arr)) * stdev\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "areas_all = df_all.groupby(['WindDirection_deg', 'WindSpeed_m/s', '12hr-SNOWFALL_bin']).size().reset_index(name='counts')\n",
    "print(areas_all)\n",
    "fig2 = plt.figure(figsize=(15,20))\n",
    "fig2.subplots_adjust(hspace=0.4, wspace=0.1)\n",
    "\n",
    "ax2 = fig2.add_subplot(1, 1, 1, projection='polar')\n",
    "\n",
    "ax2.scatter(np.radians(rand_jitter(areas_all['WindDirection_deg'])), rand_jitter(areas_all['WindSpeed_m/s']), s = areas_all['counts']**2*10, c = areas_all['12hr-SNOWFALL_bin'], cmap='Reds', vmin=2, vmax=8, alpha = 1)\n",
    "\n",
    "plt.title(\"Ski Season Snowfall by Wind Direction\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_bin_counts = df_all.dropna().groupby(['WindDirection_deg', '12hr-SNOWFALL_bin']).size().reset_index(name='counts')\n",
    "wd_bin_counts2 = wd_bin_counts.groupby(['WindDirection_deg']).agg(['sum'])\n",
    "print(wd_bin_counts)\n",
    "print(wd_bin_counts2) \n",
    "##\n",
    "\n",
    "from scipy.stats import chisquare\n",
    "cs, pv = chisquare(wd_bin_counts2['counts'], wd_bin_counts2['counts'].mean())\n",
    "\n",
    "print('The chi square test tests the null hypothesis that the categorical data has the given frequencies.')\n",
    "print(f'Chi-square Statistic : {cs} ,p-value: {pv}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(wd_bin_counts['WindDirection_deg'], wd_bin_counts['counts'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import interpolate\n",
    "\n",
    "counts = wd_bin_counts2['counts']\n",
    "\n",
    "print(counts.head())\n",
    "plt.figure(figsize=(20,10))\n",
    "def simulate_poisson(counts):\n",
    "    # Mean is 1.69\n",
    "    mu = counts.mean()\n",
    "    print(mu)\n",
    "    sigma = sp.sqrt(mu)\n",
    "    print(sigma)\n",
    "    mu_plus_sigma = mu + sigma\n",
    "\n",
    "    # Draw random samples from the Poisson distribution, to simulate\n",
    "    # the observed events per 2 second interval.\n",
    "    counts = stats.poisson.rvs(mu, size=10000)\n",
    "\n",
    "    # Bins for the histogram: only the last bin is closed on both\n",
    "    # sides. We need one more bin than the maximum value of count, so\n",
    "    # that the maximum value goes in its own bin instead of getting\n",
    "    # added to the previous bin.\n",
    "    # [0,1), [1, 2), ..., [max(counts), max(counts)+1]\n",
    "    bins = range(0, max(counts)+2)\n",
    "\n",
    "    # Plot histogram.\n",
    "    plt.hist(counts, bins=bins, align=\"left\", histtype=\"step\", color=\"black\")\n",
    "\n",
    "    # Create Poisson distribution for given mu.\n",
    "    x = range(0,100)\n",
    "    prob = stats.poisson.pmf(x, mu)*10000\n",
    "\n",
    "    # Plot the PMF.\n",
    "    plt.plot(x, prob, \"o\", color=\"black\")\n",
    "\n",
    "    # Draw a smooth curve through the PMF.\n",
    "    l = sp.linspace(0,51,10000)\n",
    "    s = interpolate.spline(x, prob, l)\n",
    "    plt.plot(l,s,color=\"black\")\n",
    "\n",
    "    plt.xlabel(\"Number of counts per 2 seconds\")\n",
    "    plt.ylabel(\"Number of occurrences (Poisson)\")\n",
    "\n",
    "    # Interpolated probability at x = μ + σ; for marking σ in the graph.\n",
    "   # xx = sp.searchsorted(l,mu_plus_sigma) - 1\n",
    "    #v = ((s[xx+1] -  s[xx])/(l[xx+1]-l[xx])) * (mu_plus_sigma - l[xx])\n",
    "    #v += s[xx]\n",
    "\n",
    "    #ax = plt.gca()\n",
    "    # Reset axis range and ticks.\n",
    "    #ax.axis([-0.5,10, 0, 40])\n",
    "    #ax.set_xticks(range(1,10), minor=True)\n",
    "    #ax.set_yticks(range(0,41,8))\n",
    "    #ax.set_yticks(range(4,41,8), minor=True)\n",
    "\n",
    "    # Draw arrow and then place an opaque box with μ in it.\n",
    "    #ax.annotate(\"\", xy=(mu,29), xycoords=\"data\", xytext=(mu, 13),\n",
    "    #            textcoords=\"data\", arrowprops=dict(arrowstyle=\"->\",\n",
    "    #                                               connectionstyle=\"arc3\"))\n",
    "    #bbox_props = dict(boxstyle=\"round\", fc=\"w\", ec=\"w\")\n",
    "    #ax.text(mu, 21, r\"$\\mu$\", va=\"center\", ha=\"center\",\n",
    "     #       size=15, bbox=bbox_props)\n",
    "\n",
    "    # Draw arrow and then place an opaque box with σ in it.\n",
    "    #x.annotate(\"\", xy=(mu,v), xytext=(mu_plus_sigma,v),\n",
    "    #            arrowprops=dict(arrowstyle=\"<->\", connectionstyle=\"arc3\"))\n",
    "    #box_props = dict(boxstyle=\"round\", fc=\"w\", ec=\"w\")\n",
    "    #ax.text(mu+(sigma/2.0), v, r\"$\\sigma$\", va=\"center\", ha=\"center\",\n",
    "     #       size=15, bbox=bbox_props)\n",
    "\n",
    "    # Refresh plot and save figure.\n",
    "    #plt.draw()\n",
    "#    plt.savefig(\"simulate_poisson.png\")\n",
    "\n",
    "simulate_poisson(counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
