{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import necessary modules and the ASOS/SNOTEL dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit: None\n",
      "python: 3.6.5.final.0\n",
      "python-bits: 32\n",
      "OS: Windows\n",
      "OS-release: 10\n",
      "machine: AMD64\n",
      "processor: Intel64 Family 6 Model 142 Stepping 9, GenuineIntel\n",
      "byteorder: little\n",
      "LC_ALL: None\n",
      "LANG: en_US.UTF-8\n",
      "LOCALE: None.None\n",
      "\n",
      "pandas: 0.24.0\n",
      "pytest: None\n",
      "pip: 18.1\n",
      "setuptools: 39.0.1\n",
      "Cython: None\n",
      "numpy: 1.14.3\n",
      "scipy: 1.1.0\n",
      "pyarrow: None\n",
      "xarray: None\n",
      "IPython: 6.4.0\n",
      "sphinx: None\n",
      "patsy: 0.5.1\n",
      "dateutil: 2.7.3\n",
      "pytz: 2018.4\n",
      "blosc: None\n",
      "bottleneck: None\n",
      "tables: None\n",
      "numexpr: None\n",
      "feather: None\n",
      "matplotlib: 2.2.2\n",
      "openpyxl: None\n",
      "xlrd: None\n",
      "xlwt: None\n",
      "xlsxwriter: None\n",
      "lxml.etree: 4.2.5\n",
      "bs4: None\n",
      "html5lib: 1.0.1\n",
      "sqlalchemy: None\n",
      "pymysql: None\n",
      "psycopg2: None\n",
      "jinja2: 2.10\n",
      "s3fs: None\n",
      "fastparquet: None\n",
      "pandas_gbq: None\n",
      "pandas_datareader: None\n",
      "gcsfs: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\users\\\\rapp\\\\appdata\\\\local\\\\programs\\\\python\\\\python36-32\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime as dtb\n",
    "import os\n",
    "from glob import glob\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "pd.show_versions()\n",
    "import sys\n",
    "import graphviz\n",
    "sys.executable\n",
    "#import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\RAPP\\\\Documents\\\\Capstone\\\\Projects\\\\model_predictions\\\\A0-SFC_0617Train_OLS.csv', 'C:\\\\Users\\\\RAPP\\\\Documents\\\\Capstone\\\\Projects\\\\model_predictions\\\\A0-UASFC_0617Train_OLS.csv', 'C:\\\\Users\\\\RAPP\\\\Documents\\\\Capstone\\\\Projects\\\\model_predictions\\\\B0-SFC_2014Train_OLS.csv', 'C:\\\\Users\\\\RAPP\\\\Documents\\\\Capstone\\\\Projects\\\\model_predictions\\\\B0-UASFC_2014Train_OLS.csv', 'C:\\\\Users\\\\RAPP\\\\Documents\\\\Capstone\\\\Projects\\\\model_predictions\\\\SFC-0617Train_CVRidge.csv', 'C:\\\\Users\\\\RAPP\\\\Documents\\\\Capstone\\\\Projects\\\\model_predictions\\\\SFC-2014Train_CVRidge.csv', 'C:\\\\Users\\\\RAPP\\\\Documents\\\\Capstone\\\\Projects\\\\model_predictions\\\\UASFC-0617Train_CVRidge.csv', 'C:\\\\Users\\\\RAPP\\\\Documents\\\\Capstone\\\\Projects\\\\model_predictions\\\\UASFC-2014Train_CVRidge.csv']\n",
      "A0-SFC\n",
      "['A0-SFC', 'A0-UASFC', 'B0-SFC', 'B0-UASFC', 'SFC-0617Train', 'SFC-2014Train', 'UASFC-0617Train', 'UASFC-2014Train']\n",
      "4.930232558139535\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "dataframe = pd.DataFrame()\n",
    "#descriptors = ['OLS_SFC_0617Train', 'OLS_SFC_2014Train', 'OLS_UASFC_0617Train', 'OLS_UASFC_2014Train', \\\n",
    "#               'CV_OLS_SFC_0617Train', 'CV_OLS_SFC_0617Train_noWD', 'CV_OLS_SFC_2014Train', 'CV_OLS_2014Train_noWD','CV_OLS_UASFCTrain_0617', \\\n",
    "#               'CV_OLS_UASFC_1617Train_noWD', 'CV_OLS_UASFCTrain_2014',  'CV_OLS_UASFCTrain_2014_noWD']\n",
    "\n",
    "\n",
    "filenames = glob(r'C:\\Users\\RAPP\\Documents\\Capstone\\Projects\\model_predictions\\*.csv')\n",
    "print(filenames)\n",
    "#print(str(filenames[0].find('.'))+':'+str(filenames[0].rfind('/')))\n",
    "\n",
    "descriptors =  [fn[(fn.rfind('\\\\')+1):fn.rfind('.csv')] for fn in filenames]\n",
    "print(descriptors[0][0:6])\n",
    "IDs = [id[0:id.find('_')] for id in descriptors]\n",
    "print(IDs)\n",
    "\n",
    "\n",
    "\n",
    "model_data = [pd.read_csv(filename, header = None, names = ['actual_snf', 'predicted_snf']) for filename in filenames]\n",
    "#print(list_of_dfs)\n",
    "\n",
    "print(model_data[1]['actual_snf'].mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x0E0D5480>\n",
      "[]\n",
      "[1.587773166214191, 1.6549032917194861, 1.8791345466207543, 2.280856896418228, 1.7758776729678325, 1.9795081172218345, 1.7614208276600694, 1.9755401270873552] [0.29825911369991104, 0.33475848859256685, 0.29442106526097106, 0.38416945217976917, 0.35279516551065165, 0.3039741720900174, 0.3516088718280559, 0.3050776919583422] [-0.06531587637715447, -0.1126846251237679, 0.06235237653048953, 0.08174592149490954, -0.1169658043702861, 0.09178676633074996, -0.12183592987875855, 0.08954386700451128]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit # import KFold\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "\n",
    "from scipy.stats import pearsonr, linregress\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from regressors import stats\n",
    "import csv  \n",
    "\n",
    "\n",
    "slopes, intercepts, r_values, p_values, std_errs, mses, rmses = [],[],[],[],[], [], [] \n",
    "R2_scores, accuracys, rmse_w_mean_actual_snfs =[], [], []\n",
    "maes, mpes, mapes, means_actual, means_predict = [], [], [], [], []\n",
    "all_Ytest_predictions, all_Ytests = [], []\n",
    "all_Ytest_predictions_arrays, all_Ytests_arrays = [],[]\n",
    "Ytest_predictions = []    \n",
    "\n",
    "\n",
    "#Loop through\n",
    "for scenario in np.arange(0,len(model_data),1):\n",
    " \n",
    " actual_snf = model_data[scenario]['actual_snf']\n",
    " predicted_snf = model_data[scenario]['predicted_snf']\n",
    "\n",
    "\n",
    "  \n",
    " R2_scores.append(r2_score( actual_snf,predicted_snf,))\n",
    " slope, intercept, r_value, p_value, std_err = linregress(predicted_snf, actual_snf)    \n",
    " slopes.append(slope)\n",
    " intercepts.append(intercept)\n",
    " r_values.append(r_value)\n",
    " p_values.append(p_value)\n",
    " std_errs.append(std_err)\n",
    " mses.append(mean_squared_error(actual_snf, predicted_snf)) \n",
    " rmses.append(np.sqrt(mean_squared_error(actual_snf, predicted_snf)))\n",
    " all_Ytest_predictions_arrays.append(Ytest_predictions)   #creates list of arrays\n",
    " all_Ytests_arrays.append(actual_snf)   #creates list of arrays\n",
    " #print(str(R2_scores))\n",
    "    \n",
    "\n",
    "#Calculate Mean Absolute Error\n",
    " mae_sum = np.sum(abs(actual_snf-predicted_snf))\n",
    " maes.append(mae_sum/len(actual_snf))\n",
    "\n",
    "#Calculate Mean Absolute Percentage Error\n",
    " mape_sum = np.sum(abs((actual_snf-predicted_snf)/actual_snf))\n",
    " mapes.append(mape_sum/len(actual_snf))\n",
    "\n",
    "#Calcluate Mean Percentage Error\n",
    " mpe_sum = np.sum((actual_snf-predicted_snf)/actual_snf)\n",
    " mpes.append(mpe_sum/len(actual_snf))        \n",
    "\n",
    "\n",
    "#Calculate mean\n",
    " means_actual.append(actual_snf.mean())\n",
    " means_predict.append(predicted_snf.mean())\n",
    "\n",
    " #Calculate RMSE if mean snowfall of dataset is used\n",
    " rmse_w_mean_actual_snfs.append(np.sqrt(mean_squared_error([actual_snf.mean()]*len(actual_snf), actual_snf)))\n",
    "\n",
    " #print('Mean Cross Val R2 score: '+ str(R2_scores))\n",
    " #print('Mean RMSE:' + str(rmses))\n",
    "#print(accuracys)\n",
    "print(x.mean for x in accuracys) \n",
    "print([np.mean(x) for x in np.abs(accuracys)])\n",
    "print(maes, mapes, mpes)\n",
    "    \n",
    "#all_Ytest_predictions = [val for sublist in  all_Ytest_predictions_arrays for val in sublist]   #flattens list of arrays into single list of values\n",
    "#all_Ytests = [val for sublist in   all_Ytests_arrays for val in sublist]   #flattens list of arrays into single list of values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID              | Model Data              |   R2 Score |   R Squared |   p vaue |   RMSE |   MAE |   MAPE |    MPE |   Actual Mean |   Predicted Mean |   RMSE with mean actual snowfall |\n",
      "|-----------------|-------------------------|------------|-------------|----------|--------|-------|--------|--------|---------------|------------------|----------------------------------|\n",
      "| A0-SFC          | A0-SFC_0617Train_OLS    |      0.046 |       0.088 |    0.053 |  2.6   | 1.588 |  0.298 | -0.065 |         4.93  |            4.443 |                            2.662 |\n",
      "| A0-UASFC        | A0-UASFC_0617Train_OLS  |      0.128 |       0.135 |    0.015 |  2.487 | 1.655 |  0.335 | -0.113 |         4.93  |            4.7   |                            2.662 |\n",
      "| B0-SFC          | B0-SFC_2014Train_OLS    |     -0.174 |       0.019 |    0.412 |  2.785 | 1.879 |  0.294 |  0.062 |         5.716 |            4.59  |                            2.57  |\n",
      "| B0-UASFC        | B0-UASFC_2014Train_OLS  |     -0.412 |       0.001 |    0.837 |  3.055 | 2.281 |  0.384 |  0.082 |         5.716 |            4.441 |                            2.57  |\n",
      "| SFC-0617Train   | SFC-0617Train_CVRidge   |      0.004 |       0.104 |    0.035 |  2.657 | 1.776 |  0.353 | -0.117 |         4.93  |            4.594 |                            2.662 |\n",
      "| SFC-2014Train   | SFC-2014Train_CVRidge   |     -0.256 |       0.002 |    0.785 |  2.885 | 1.98  |  0.304 |  0.092 |         5.73  |            4.423 |                            2.575 |\n",
      "| UASFC-0617Train | UASFC-0617Train_CVRidge |      0.017 |       0.077 |    0.072 |  2.64  | 1.761 |  0.352 | -0.122 |         4.93  |            4.621 |                            2.662 |\n",
      "| UASFC-2014Train | UASFC-2014Train_CVRidge |     -0.234 |       0.017 |    0.438 |  2.861 | 1.976 |  0.305 |  0.09  |         5.73  |            4.441 |                            2.575 |\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "tbl = zip(IDs, descriptors, np.round(R2_scores,3), np.round([i ** 2 for i in r_values],3), np.round(p_values,3), np.round(rmses,3),  np.round(maes,3), np.round(mapes,3), np.round(mpes,3), np.round(means_actual,3),  np.round(means_predict,3), np.round(rmse_w_mean_actual_snfs,3))  \n",
    "print(tabulate(tbl, headers=['ID', 'Model Data', 'R2 Score','R Squared', \"p vaue\", 'RMSE', 'MAE','MAPE', 'MPE', 'Actual Mean', 'Predicted Mean', 'RMSE with mean actual snowfall'], tablefmt='github'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make some plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, False, True, False, False, False, False, False]\n",
      "[False, True, False, True, False, False, False, False]\n",
      "2\n",
      "2\n",
      "[True, True, True, True, True, True, True, True]\n",
      "[0 1 2 3]\n",
      "0       A0-SFC_0617Train_OLS\n",
      "1     A0-UASFC_0617Train_OLS\n",
      "2       B0-SFC_2014Train_OLS\n",
      "3     B0-UASFC_2014Train_OLS\n",
      "4      SFC-0617Train_CVRidge\n",
      "5      SFC-2014Train_CVRidge\n",
      "6    UASFC-0617Train_CVRidge\n",
      "7    UASFC-2014Train_CVRidge\n",
      "Name: Model_Data, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f09fc6d4cc29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#plt.bar(x, y, width, color=\"blue\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummary_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'R2_Score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msfc_bars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtick_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][sfc_bars]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummary_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'R2_Score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muasfc_bars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtick_label\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][uasfc_bars]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rapp\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2768\u001b[0m                       mplDeprecation)\n\u001b[0;32m   2769\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2770\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2771\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2772\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rapp\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mc:\\users\\rapp\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2231\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[0;32m   2232\u001b[0m             \u001b[1;31m# Make args iterable too.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2233\u001b[1;33m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[0;32m   2234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2235\u001b[0m         \u001b[1;31m# Now that units have been converted, set the tick locations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rapp\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rapp\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;31m# consistently\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m     \u001b[1;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tbl = zip(IDs, descriptors, R2_scores, [i ** 2 for i in r_values], p_values, rmses, maes, mapes, mpes, means_actual, means_predict, rmse_w_mean_actual_snfs )  \n",
    "summary_df = pd.DataFrame(tbl, columns = ['IDs', 'Model_Data', 'R2_Score','R_Squared', \"p_value\", 'RMSE', 'MAE','MAPE', 'MPE', 'Actual_Mean', 'Predicted_Mean', 'RMSE_with_mean_actual_snowfall'])\n",
    "#print(summary_df)\n",
    "idx = [s.find('lowp')<0 for s in summary_df.Model_Data]\n",
    "#print(idx)\n",
    "sfc_bars =  [s.find('-SFC')>=0 for s in summary_df.Model_Data[idx]]\n",
    "uasfc_bars =  [s.find('-UASFC')>=0 for s in summary_df.Model_Data[idx]]\n",
    "print(sfc_bars)\n",
    "print(uasfc_bars)\n",
    "print(len(summary_df['RMSE'][idx][sfc_bars]))\n",
    "print(len(summary_df['RMSE'][idx][uasfc_bars]))\n",
    "\n",
    "#plt.bar(summary_df['R2_Score'][idx][sfc_bars])\n",
    "labels = ['A0', 'A1', 'B0', 'B1']\n",
    "print(idx)\n",
    "\n",
    "pos = np.arange(4)\n",
    "print(pos)\n",
    "\n",
    "print(summary_df['Model_Data'])\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "width = 0.4\n",
    "ax = plt.subplot(1,1,1)\n",
    "#plt.bar(x, y, width, color=\"blue\")\n",
    "plt.bar([p + 0 for p in pos], summary_df['R2_Score'][idx][sfc_bars], width, tick_label = labels)  #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][sfc_bars]])\n",
    "plt.bar([p + width for p in pos], summary_df['R2_Score'][idx][uasfc_bars],  width, tick_label= labels) #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][uasfc_bars]])\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "#plt.ylabel('Scikit-learn R2 Score')\n",
    "plt.xlabel('Model ID')\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_xticks([p + 1 * width/2 for p in pos])\n",
    "plt.xlim(min(pos)-width, max(pos)+width/2*4)\n",
    "\n",
    "\n",
    "plt.legend(['Surface Data', 'Surface+Upper Air'], loc='upper right')\n",
    "plt.savefig('C:/Users/RAPP/Documents/Capstone/Report/figs/R2_Score_summary.png', bbox_inches='tight')\n",
    "\n",
    "plt.title('Scikit-learn R2 Score Comparisions of OLS Model Runs')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "plt.bar([p + 0 for p in pos], summary_df['RMSE'][idx][sfc_bars], width, tick_label = labels)  #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][sfc_bars]])\n",
    "plt.bar([p + width for p in pos], summary_df['RMSE'][idx][uasfc_bars],  width, tick_label= labels) #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][uasfc_bars]])\n",
    "plt.xticks(rotation=0) #, rotation_mode=\"default\", ha = 'left', va = 'bottom')\n",
    "plt.annotate('RMSE Using Climatology', xy=(2, 2.17), color = 'r')\n",
    "plt.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.ylabel('RMSE inches')\n",
    "plt.xticks(rotation=45)\n",
    "#plt.xlabel('Model ID')\n",
    "\n",
    "ax.set_xticks([p + 1 * width/2 for p in pos])\n",
    "plt.xlim(min(pos)-width, max(pos)+width/2*5)\n",
    "plt.hlines(2.15, 0,3.5, color = 'r')\n",
    "plt.savefig('C:/Users/RAPP/Documents/Capstone/Report/figs/RMSE_summary.png', bbox_inches='tight')\n",
    "\n",
    "plt.title('RMSE Comparisions of OLS Model Runs')\n",
    "plt.show\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "plt.bar([p + 0 for p in pos], summary_df['MAE'][idx][sfc_bars], width, tick_label = labels)  #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][sfc_bars]])\n",
    "plt.bar([p + width for p in pos], summary_df['MAE'][idx][uasfc_bars],  width, tick_label= labels) #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][uasfc_bars]])\n",
    "plt.xticks(rotation=0) #, rotation_mode=\"default\", ha = 'left', va = 'bottom')\n",
    "\n",
    "plt.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.ylabel('MAE (inches)')\n",
    "plt.xticks(rotation=45)\n",
    "#plt.xlabel('Model ID')\n",
    "\n",
    "ax.set_xticks([p + 1 * width/2 for p in pos])\n",
    "plt.xlim(min(pos)-width, max(pos)+width/2*2)\n",
    "#plt.hlines(2.15, 0,3.5, color = 'r')\n",
    "plt.savefig('C:/Users/RAPP/Documents/Capstone/Report/figs/MAE_summary.png', bbox_inches='tight')\n",
    "\n",
    "plt.title('MAE Comparisions of OLS Model Runs')\n",
    "plt.show\n",
    "\n",
    "#***********************************************************************\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "plt.bar([p + 0 for p in pos], summary_df['MPE'][idx][sfc_bars], width, tick_label = labels)  #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][sfc_bars]])\n",
    "plt.bar([p + width for p in pos], summary_df['MPE'][idx][uasfc_bars],  width, tick_label= labels) #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][uasfc_bars]])\n",
    "plt.xticks(rotation=0) #, rotation_mode=\"default\", ha = 'left', va = 'bottom')\n",
    "\n",
    "plt.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.ylabel('MAE (inches)')\n",
    "plt.xticks(rotation=45)\n",
    "#plt.xlabel('Model ID')\n",
    "\n",
    "ax.set_xticks([p + 1 * width/2 for p in pos])\n",
    "plt.xlim(min(pos)-width, max(pos)+width/2*2)\n",
    "#plt.hlines(2.15, 0,3.5, color = 'r')\n",
    "plt.savefig('C:/Users/RAPP/Documents/Capstone/Report/figs/MPE_summary.png', bbox_inches='tight')\n",
    "\n",
    "plt.title('MPE Comparisions of OLS Model Runs')\n",
    "plt.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = zip(IDs, descriptors, R2_scores, [i ** 2 for i in r_values], p_values, rmses, maes, mapes, mpes, means_actual, means_predict, rmse_w_mean_actual_snfs )  \n",
    "summary_df = pd.DataFrame(tbl, columns = ['IDs', 'Model_Data', 'R2_Score','R_Squared', \"p_value\", 'RMSE', 'MAE','MAPE', 'MPE', 'Actual_Mean', 'Predicted_Mean', 'RMSE_with_mean_actual_snowfall'])\n",
    "#print(summary_df)\n",
    "idx = [s.find('lowp')<0 for s in summary_df.Model_Data]\n",
    "#print(idx)\n",
    "sfc_bars =  [s.find('-SFC')>=0 for s in summary_df.Model_Data[idx]]\n",
    "uasfc_bars =  [s.find('-UASFC')>=0 for s in summary_df.Model_Data[idx]]\n",
    "\n",
    "\n",
    "\n",
    "labels = ['Model A Features', 'Model A Feature A\\n(low p values)', 'Model B Features',  'Model B Features\\n(low p values)']\n",
    "print(idx)\n",
    "\n",
    "pos = np.arange(4)\n",
    "print(pos)\n",
    "\n",
    "print(summary_df['Model_Data'])\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "width = 0.4\n",
    "ax = plt.subplot(1,1,1)\n",
    "#plt.bar(x, y, width, color=\"blue\")\n",
    "plt.bar([p + 0 for p in pos], summary_df['R2_Score'][idx][sfc_bars], width, tick_label = labels)  #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][sfc_bars]])\n",
    "plt.bar([p + width for p in pos], summary_df['R2_Score'][idx][uasfc_bars],  width, tick_label= labels) #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][uasfc_bars]])\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "#plt.ylabel('Scikit-learn R2 Score')\n",
    "plt.xlabel('Model ID')\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_xticks([p + 1 * width/2 for p in pos])\n",
    "plt.xlim(min(pos)-width, max(pos)+width/2*4)\n",
    "\n",
    "\n",
    "plt.legend(['Surface Data', 'Surface+Upper Air'], loc='upper right')\n",
    "plt.savefig('C:/Users/RAPP/Documents/Capstone/Report/figs/R2_Score_summary_CV.png', bbox_inches='tight')\n",
    "\n",
    "plt.title('Scikit-learn R2 Score Comparisions of OLS Model Runs')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "plt.bar([p + 0 for p in pos], summary_df['RMSE'][idx][sfc_bars], width, tick_label = labels)  #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][sfc_bars]])\n",
    "plt.bar([p + width for p in pos], summary_df['RMSE'][idx][uasfc_bars],  width, tick_label= labels) #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][uasfc_bars]])\n",
    "plt.xticks(rotation=0) #, rotation_mode=\"default\", ha = 'left', va = 'bottom')\n",
    "plt.annotate('RMSE Using Climatology', xy=(2, 2.17), color = 'r')\n",
    "plt.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.ylabel('RMSE inches')\n",
    "plt.xticks(rotation=45)\n",
    "#plt.xlabel('Model ID')\n",
    "\n",
    "ax.set_xticks([p + 1 * width/2 for p in pos])\n",
    "plt.xlim(min(pos)-width, max(pos)+width/2*4)\n",
    "plt.hlines(2.15, 0,3.5, color = 'r')\n",
    "plt.savefig('C:/Users/RAPP/Documents/Capstone/Report/figs/RMSE_summary_CV.png', bbox_inches='tight')\n",
    "\n",
    "plt.title('RMSE Comparisions of OLS Model Runs')\n",
    "plt.show\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "plt.bar([p + 0 for p in pos], summary_df['MAE'][idx][sfc_bars], width, tick_label = labels)  #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][sfc_bars]])\n",
    "plt.bar([p + width for p in pos], summary_df['MAE'][idx][uasfc_bars],  width, tick_label= labels) #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][uasfc_bars]])\n",
    "plt.xticks(rotation=0) #, rotation_mode=\"default\", ha = 'left', va = 'bottom')\n",
    "\n",
    "plt.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.ylabel('MAE (inches)')\n",
    "plt.xticks(rotation=45)\n",
    "#plt.xlabel('Model ID')\n",
    "\n",
    "ax.set_xticks([p + 1 * width/2 for p in pos])\n",
    "plt.xlim(min(pos)-width, max(pos)+width/2*4)\n",
    "#plt.hlines(2.15, 0,3.5, color = 'r')\n",
    "plt.savefig('C:/Users/RAPP/Documents/Capstone/Report/figs/MAE_summary_CV.png', bbox_inches='tight')\n",
    "\n",
    "plt.title('MAE Comparisions of OLS Model Runs')\n",
    "plt.show\n",
    "\n",
    "#***********************************************************************\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "plt.bar([p + 0 for p in pos], summary_df['MPE'][idx][sfc_bars], width, tick_label = labels)  #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][sfc_bars]])\n",
    "plt.bar([p + width for p in pos], summary_df['MPE'][idx][uasfc_bars],  width, tick_label= labels) #  tick_label = [x.rstrip() for x in summary_df['IDs'][idx][uasfc_bars]])\n",
    "plt.xticks(rotation=0) #, rotation_mode=\"default\", ha = 'left', va = 'bottom')\n",
    "\n",
    "plt.grid(True)\n",
    "ax.set_axisbelow(True)\n",
    "plt.ylabel('MAE (inches)')\n",
    "plt.xticks(rotation=45)\n",
    "#plt.xlabel('Model ID')\n",
    "\n",
    "ax.set_xticks([p + 1 * width/2 for p in pos])\n",
    "plt.xlim(min(pos)-width, max(pos)+width/2*4)\n",
    "#plt.hlines(2.15, 0,3.5, color = 'r')\n",
    "plt.savefig('C:/Users/RAPP/Documents/Capstone/Report/figs/MPE_summary_CV.png', bbox_inches='tight')\n",
    "\n",
    "plt.title('MPE Comparisions of OLS Model Runs')\n",
    "plt.show\n",
    "\n",
    "#print([x.rstrip() for x in summary_df['Description ']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regressors\n",
    "print(descriptors)\n",
    "for scenario in np.arange(0,len(model_data),1):\n",
    "    print(descriptors[scenario])\n",
    "\n",
    "for scenario in np.arange(0,len(model_data),1):\n",
    "    actual_snf = model_data[scenario]['actual_snf']\n",
    "    predicted_snf = model_data[scenario]['predicted_snf']\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    sns.regplot(model_data[scenario]['predicted_snf'],model_data[scenario]['actual_snf'])\n",
    "    \n",
    "    \n",
    "    bbox_props=dict(facecolor='red', alpha=0.75, fc = 'white')\n",
    "    plt.annotate(' slope: ' + str(round(slopes[scenario],3)) +\n",
    "                 '\\n intercept (of fit line): ' + str(round(intercepts[scenario],3)) + \n",
    "                 '\\n R squared (of fit line): ' + str(round(r_values[scenario]**2,3)) +  \n",
    "                 '\\n p value (of fit line): ' +  str(format(p_values[scenario], \"10.2E\")) + \n",
    "                 '\\n standard error (of fit line): ' + str(round(std_errs[scenario],3)) +\n",
    "                 '\\n mean squared error: ' + str(round(mses[scenario],3)) +\n",
    "                 '\\n root mean squared error: ' + str(round(rmses[scenario],3)), \\\n",
    "                 xy=(0.02, 0.74), xycoords='axes fraction', fontsize=10, bbox = bbox_props)\n",
    "\n",
    "    plt.xlabel('Predicted Snowfall (inches)')\n",
    "    plt.ylabel('Actual Snowfall (inches)')\n",
    "    plt.xlim([2,8])\n",
    "    plt.ylim([0,17])\n",
    "    plt.grid(True)\n",
    "    plt.savefig('C:/Users/RAPP/Documents/Capstone/Report/figs/pred_vs_act_'+descriptors[scenario]+'.png',bbox_inches='tight')\n",
    "    plt.title(descriptors[scenario]+'\\nPredicted vs Actual Snowfall Amounts', fontsize = 16)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in np.arange(0, len(model_data), 1):\n",
    "    \n",
    "   actual_snf = model_data[scenario]['actual_snf']\n",
    "   predicted_snf = model_data[scenario]['predicted_snf'] \n",
    "    \n",
    "   fig = plt.figure(figsize=(8,5))\n",
    "\n",
    "   plt.scatter(predicted_snf, actual_snf - predicted_snf)\n",
    "\n",
    "   plt.ylabel('Actual - Predicted Snowfall (inches)')\n",
    "   plt.xlabel('Predicted Snowfall (inches)')\n",
    "   plt.xlim([2,7])\n",
    "   plt.ylim([-3,13])\n",
    "   plt.grid(True)\n",
    "   plt.savefig('C:/Users/RAPP/Documents/Capstone/Report/figs/resid_vs_pred_'+descriptors[scenario]+'.png',bbox_inches='tight')\n",
    "   plt.title(descriptors[scenario]+'\\nPredicted Snowfall Amounts vs Residuals', fontsize = 16)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "for scenario in np.arange(0, len(model_data), 1):\n",
    "       actual_snf = model_data[scenario]['actual_snf']\n",
    "       predicted_snf = model_data[scenario]['predicted_snf'] \n",
    "\n",
    "\n",
    "       residuals = actual_snf - predicted_snf \n",
    "       fig, ax = plt.subplots(figsize=(8, 5))\n",
    "       qq2=sm.qqplot(residuals, line='45', ax = ax)    \n",
    "       plt.ylim([-5,12])\n",
    "\n",
    "       plt.grid(True)\n",
    "       plt.grid(True)\n",
    "       plt.savefig('C:/Users/RAPP/Documents/Capstone/Report/figs/qq_resid_'+descriptors[scenario]+'.png',bbox_inches='tight')\n",
    "       plt.title(descriptors[scenario]+'\\nTheoretical vs Sample Quantiles of Residuals', fontsize = 16)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in np.arange(0, len(model_data), 1):\n",
    "  actual_snf = model_data[scenario]['actual_snf']\n",
    "  predicted_snf = model_data[scenario]['predicted_snf'] \n",
    "\n",
    "  diff =  actual_snf - predicted_snf\n",
    "  \n",
    "  fig = plt.figure(figsize=(8, 5))\n",
    "  ax = plt.subplot(1,1,1)\n",
    "\n",
    "  weights = np.ones_like(diff)/float(len(diff))\n",
    "  plt.hist(diff, histtype = 'bar', weights=weights*100, \\\n",
    "           bins = np.arange(-4,14,1), align = 'mid', edgecolor = 'black') \n",
    "\n",
    "  plt.xlabel('Actual - Predicted Snowfall (inches)')\n",
    "  plt.ylabel('Percent of Total')\n",
    "  plt.xlim([-4,14])\n",
    "\n",
    "  plt.xticks(np.arange(-4,14,1))\n",
    "  plt.yticks(np.arange(0,46,5))\n",
    "  ax.set_axisbelow(True)   #places gridlines behind bars\n",
    "  plt.grid(True, axis = 'y')\n",
    "\n",
    "\n",
    "  plt.title('', fontsize = 16)\n",
    "  plt.savefig('C:/Users/RAPP/Documents/Capstone/Report/figs/hist_actual_minus_pred_'+descriptors[scenario]+'.png',bbox_inches='tight')\n",
    "  plt.title(descriptors[scenario]+'\\nHistogram of Residuals', fontsize = 16)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
